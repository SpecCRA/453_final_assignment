{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MSDS Assignment 4: Sentiment Analysis of Amazon Reviews\n",
    "## Category: Video games\n",
    "## Author: Ben Xiao"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Setup #######\n",
    "# Import packages\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re, string\n",
    "import nltk\n",
    "import gensim\n",
    "import multiprocessing\n",
    "import matplotlib\n",
    "import sklearn\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import support libraries\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict\n",
    "\n",
    "# Import sklearn things\n",
    "from sklearn.model_selection import KFold, cross_validate, cross_val_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import f1_score, mean_squared_error\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "\n",
    "# Import Keras things\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Embedding, Input, Conv1D, MaxPooling1D, LSTM, \\\n",
    "                                        GRU, Dropout, BatchNormalization, Dense, \\\n",
    "                                        Flatten, GlobalMaxPooling1D, Bidirectional, \\\n",
    "                                        LeakyReLU\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import RMSprop, Adagrad, Adam, SGD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Check package version:\nPython: 3.8.2 (default, Apr 27 2020, 15:53:34) \n[GCC 9.3.0]\npandas: 1.0.3\nNumPy: 1.18.3\nReGex: 2.2.1\nscikit-learn: 0.22.2.post1\nmatplotlib: 3.2.1\n"
    }
   ],
   "source": [
    "# Check package versions\n",
    "print('Check package version:')\n",
    "print('Python: {}'.format(sys.version))\n",
    "print('pandas: {}'.format(pd.__version__))\n",
    "print('NumPy: {}'.format(np.__version__))\n",
    "print('ReGex: {}'.format(re.__version__))\n",
    "print('scikit-learn: {}'.format(sklearn.__version__))\n",
    "print('matplotlib: {}'.format(matplotlib.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text parsing settings\n",
    "STEMMING = False\n",
    "seed = 88\n",
    "cores = multiprocessing.cpu_count()\n",
    "np.random.seed(88)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   overall                                         reviewText        asin  \\\n0        1  I used to play this game years ago and loved i...  0439381673   \n1        3  The game itself worked great but the story lin...  0439381673   \n2        4  I had to learn the hard way after ordering thi...  0439381673   \n3        1  The product description should state this clea...  0439381673   \n4        4  I would recommend this learning game for anyon...  0439381673   \n\n   word_counts  \n0          139  \n1          145  \n2          447  \n3          157  \n4          120  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>overall</th>\n      <th>reviewText</th>\n      <th>asin</th>\n      <th>word_counts</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>I used to play this game years ago and loved i...</td>\n      <td>0439381673</td>\n      <td>139</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3</td>\n      <td>The game itself worked great but the story lin...</td>\n      <td>0439381673</td>\n      <td>145</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4</td>\n      <td>I had to learn the hard way after ordering thi...</td>\n      <td>0439381673</td>\n      <td>447</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>The product description should state this clea...</td>\n      <td>0439381673</td>\n      <td>157</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>I would recommend this learning game for anyon...</td>\n      <td>0439381673</td>\n      <td>120</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "# Import and check data\n",
    "data_path = 'data_files/short_reviews.pkl'\n",
    "df = pd.read_pickle(data_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################\n",
    "# DEVELOPMENT SET - comment out when done\n",
    "############################\n",
    "# shuffle dataframe rows before splitting\n",
    "df = df.sample(frac=1, random_state=seed)\n",
    "df = df.iloc[:8000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean text\n",
    "def clean_doc(doc):\n",
    "    # split document into individual words\n",
    "    tokens=doc.split()\n",
    "    re_punc = re.compile('[%s]' % re.escape(string.punctuation))\n",
    "    # remove punctuation from each word\n",
    "    tokens = [re_punc.sub('', w) for w in tokens]\n",
    "    # remove remaining tokens that are not alphabetic\n",
    "    tokens = [word for word in tokens if word.isalpha()]\n",
    "    # filter out short tokens\n",
    "    tokens = [word for word in tokens if len(word) > 2]\n",
    "    # filter out tokens more than 20 characters long\n",
    "    tokens = [word for word in tokens if len(word) < 21]\n",
    "    #lowercase all words\n",
    "    tokens = [word.lower() for word in tokens]\n",
    "    # filter out stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [w for w in tokens if not w in stop_words]\n",
    "    # word stemming Commented\n",
    "    if STEMMING:\n",
    "        ps=PorterStemmer()\n",
    "        tokens=[ps.stem(word) for word in tokens]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to record time\n",
    "def parse_time(start_time, end_time):\n",
    "    runtime = end_time - start_time\n",
    "    return round(runtime, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate documents\n",
    "docs = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Start cleaning docs...\nFinished cleaning docs...\nCleaning runtime: 1.324\n"
    }
   ],
   "source": [
    "# Clean training set\n",
    "print('Start cleaning docs...')\n",
    "start_clean = time.time()\n",
    "for i in range(len(df)):\n",
    "    temp_text = df.reviewText.iloc[i]\n",
    "    cleaned_doc = clean_doc(temp_text)\n",
    "\n",
    "    combined_text = ' '.join(cleaned_doc)\n",
    "    docs.append(combined_text)\n",
    "\n",
    "end_clean = time.time()\n",
    "print('Finished cleaning docs...')\n",
    "clean_runtime = parse_time(start_clean, end_clean)\n",
    "print('Cleaning runtime: {}'.format(clean_runtime))\n",
    "#print(docs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split into train, validation, test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = np.random.randint(0, len(df) , size = len(df))\n",
    "ind\n",
    "\n",
    "train_ind = int(0.6 * len(df)) + 1\n",
    "val_ind = int(0.2 * len(df)) + train_ind + 1\n",
    "test_ind = int(0.2 * len(df)) + val_ind - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(4801, 6402, 8001)"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "train_ind, val_ind, test_ind,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df.iloc[:train_ind]\n",
    "rf_train = df.iloc[:val_ind]\n",
    "val = df.iloc[train_ind:val_ind]\n",
    "\n",
    "test = df.iloc[val_ind:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "6402"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "len(rf_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(4801, 1601, 1598)"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "len(train), len(val), len(test) # 60, 20, 20 split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_docs = docs[:train_ind]\n",
    "rf_train_docs = docs[:val_ind]\n",
    "val_docs = docs[train_ind:val_ind]\n",
    "test_docs = docs[val_ind:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "4801"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "len(train_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check label distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "4801"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "5    2404\n4     904\n1     684\n3     455\n2     354\nName: overall, dtype: int64"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "train.overall.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<matplotlib.axes._subplots.AxesSubplot at 0x7f49df9ca910>"
     },
     "metadata": {},
     "execution_count": 20
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"250.232704pt\" version=\"1.1\" viewBox=\"0 0 381.65 250.232704\" width=\"381.65pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <defs>\n  <style type=\"text/css\">\n*{stroke-linecap:butt;stroke-linejoin:round;}\n  </style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M -0 250.232704 \nL 381.65 250.232704 \nL 381.65 0 \nL -0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 39.65 226.354579 \nL 374.45 226.354579 \nL 374.45 8.914579 \nL 39.65 8.914579 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path clip-path=\"url(#pd52ce6e341)\" d=\"M 54.868182 226.354579 \nL 85.304545 226.354579 \nL 85.304545 167.433352 \nL 54.868182 167.433352 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path clip-path=\"url(#pd52ce6e341)\" d=\"M 85.304545 226.354579 \nL 115.740909 226.354579 \nL 115.740909 226.354579 \nL 85.304545 226.354579 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path clip-path=\"url(#pd52ce6e341)\" d=\"M 115.740909 226.354579 \nL 146.177273 226.354579 \nL 146.177273 195.86026 \nL 115.740909 195.86026 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path clip-path=\"url(#pd52ce6e341)\" d=\"M 146.177273 226.354579 \nL 176.613636 226.354579 \nL 176.613636 226.354579 \nL 146.177273 226.354579 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_7\">\n    <path clip-path=\"url(#pd52ce6e341)\" d=\"M 176.613636 226.354579 \nL 207.05 226.354579 \nL 207.05 226.354579 \nL 176.613636 226.354579 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_8\">\n    <path clip-path=\"url(#pd52ce6e341)\" d=\"M 207.05 226.354579 \nL 237.486364 226.354579 \nL 237.486364 187.159903 \nL 207.05 187.159903 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_9\">\n    <path clip-path=\"url(#pd52ce6e341)\" d=\"M 237.486364 226.354579 \nL 267.922727 226.354579 \nL 267.922727 226.354579 \nL 237.486364 226.354579 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_10\">\n    <path clip-path=\"url(#pd52ce6e341)\" d=\"M 267.922727 226.354579 \nL 298.359091 226.354579 \nL 298.359091 148.482081 \nL 267.922727 148.482081 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_11\">\n    <path clip-path=\"url(#pd52ce6e341)\" d=\"M 298.359091 226.354579 \nL 328.795455 226.354579 \nL 328.795455 226.354579 \nL 298.359091 226.354579 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_12\">\n    <path clip-path=\"url(#pd52ce6e341)\" d=\"M 328.795455 226.354579 \nL 359.231818 226.354579 \nL 359.231818 19.268865 \nL 328.795455 19.268865 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"m3098876cb9\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"54.868182\" xlink:href=\"#m3098876cb9\" y=\"226.354579\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 1.0 -->\n      <defs>\n       <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n       <path d=\"M 10.6875 12.40625 \nL 21 12.40625 \nL 21 0 \nL 10.6875 0 \nz\n\" id=\"DejaVuSans-46\"/>\n       <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n      </defs>\n      <g transform=\"translate(46.916619 240.953016)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"92.913636\" xlink:href=\"#m3098876cb9\" y=\"226.354579\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 1.5 -->\n      <defs>\n       <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n      </defs>\n      <g transform=\"translate(84.962074 240.953016)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"130.959091\" xlink:href=\"#m3098876cb9\" y=\"226.354579\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 2.0 -->\n      <defs>\n       <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n      </defs>\n      <g transform=\"translate(123.007528 240.953016)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"169.004545\" xlink:href=\"#m3098876cb9\" y=\"226.354579\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 2.5 -->\n      <g transform=\"translate(161.052983 240.953016)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"207.05\" xlink:href=\"#m3098876cb9\" y=\"226.354579\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 3.0 -->\n      <defs>\n       <path d=\"M 40.578125 39.3125 \nQ 47.65625 37.796875 51.625 33 \nQ 55.609375 28.21875 55.609375 21.1875 \nQ 55.609375 10.40625 48.1875 4.484375 \nQ 40.765625 -1.421875 27.09375 -1.421875 \nQ 22.515625 -1.421875 17.65625 -0.515625 \nQ 12.796875 0.390625 7.625 2.203125 \nL 7.625 11.71875 \nQ 11.71875 9.328125 16.59375 8.109375 \nQ 21.484375 6.890625 26.8125 6.890625 \nQ 36.078125 6.890625 40.9375 10.546875 \nQ 45.796875 14.203125 45.796875 21.1875 \nQ 45.796875 27.640625 41.28125 31.265625 \nQ 36.765625 34.90625 28.71875 34.90625 \nL 20.21875 34.90625 \nL 20.21875 43.015625 \nL 29.109375 43.015625 \nQ 36.375 43.015625 40.234375 45.921875 \nQ 44.09375 48.828125 44.09375 54.296875 \nQ 44.09375 59.90625 40.109375 62.90625 \nQ 36.140625 65.921875 28.71875 65.921875 \nQ 24.65625 65.921875 20.015625 65.03125 \nQ 15.375 64.15625 9.8125 62.3125 \nL 9.8125 71.09375 \nQ 15.4375 72.65625 20.34375 73.4375 \nQ 25.25 74.21875 29.59375 74.21875 \nQ 40.828125 74.21875 47.359375 69.109375 \nQ 53.90625 64.015625 53.90625 55.328125 \nQ 53.90625 49.265625 50.4375 45.09375 \nQ 46.96875 40.921875 40.578125 39.3125 \nz\n\" id=\"DejaVuSans-51\"/>\n      </defs>\n      <g transform=\"translate(199.098438 240.953016)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"245.095455\" xlink:href=\"#m3098876cb9\" y=\"226.354579\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 3.5 -->\n      <g transform=\"translate(237.143892 240.953016)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_7\">\n     <g id=\"line2d_7\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"283.140909\" xlink:href=\"#m3098876cb9\" y=\"226.354579\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 4.0 -->\n      <defs>\n       <path d=\"M 37.796875 64.3125 \nL 12.890625 25.390625 \nL 37.796875 25.390625 \nz\nM 35.203125 72.90625 \nL 47.609375 72.90625 \nL 47.609375 25.390625 \nL 58.015625 25.390625 \nL 58.015625 17.1875 \nL 47.609375 17.1875 \nL 47.609375 0 \nL 37.796875 0 \nL 37.796875 17.1875 \nL 4.890625 17.1875 \nL 4.890625 26.703125 \nz\n\" id=\"DejaVuSans-52\"/>\n      </defs>\n      <g transform=\"translate(275.189347 240.953016)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-52\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_8\">\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"321.186364\" xlink:href=\"#m3098876cb9\" y=\"226.354579\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 4.5 -->\n      <g transform=\"translate(313.234801 240.953016)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-52\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_9\">\n     <g id=\"line2d_9\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"359.231818\" xlink:href=\"#m3098876cb9\" y=\"226.354579\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 5.0 -->\n      <g transform=\"translate(351.280256 240.953016)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_10\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"m78b45d626d\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"39.65\" xlink:href=\"#m78b45d626d\" y=\"226.354579\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 0 -->\n      <g transform=\"translate(26.2875 230.153798)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_11\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"39.65\" xlink:href=\"#m78b45d626d\" y=\"183.283507\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 500 -->\n      <g transform=\"translate(13.5625 187.082726)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"39.65\" xlink:href=\"#m78b45d626d\" y=\"140.212435\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 1000 -->\n      <g transform=\"translate(7.2 144.011654)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_13\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"39.65\" xlink:href=\"#m78b45d626d\" y=\"97.141363\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 1500 -->\n      <g transform=\"translate(7.2 100.940582)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_14\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"39.65\" xlink:href=\"#m78b45d626d\" y=\"54.070291\"/>\n      </g>\n     </g>\n     <g id=\"text_14\">\n      <!-- 2000 -->\n      <g transform=\"translate(7.2 57.86951)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_15\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"39.65\" xlink:href=\"#m78b45d626d\" y=\"10.999219\"/>\n      </g>\n     </g>\n     <g id=\"text_15\">\n      <!-- 2500 -->\n      <g transform=\"translate(7.2 14.798437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"patch_13\">\n    <path d=\"M 39.65 226.354579 \nL 39.65 8.914579 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_14\">\n    <path d=\"M 374.45 226.354579 \nL 374.45 8.914579 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_15\">\n    <path d=\"M 39.65 226.354579 \nL 374.45 226.354579 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_16\">\n    <path d=\"M 39.65 8.914579 \nL 374.45 8.914579 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"pd52ce6e341\">\n   <rect height=\"217.44\" width=\"334.8\" x=\"39.65\" y=\"8.914579\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "train.overall.hist(\n",
    "    grid=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "5    801\n4    291\n1    246\n3    153\n2    110\nName: overall, dtype: int64"
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "val.overall.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<matplotlib.axes._subplots.AxesSubplot at 0x7f49df46ed30>"
     },
     "metadata": {},
     "execution_count": 22
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"248.518125pt\" version=\"1.1\" viewBox=\"0 0 375.2875 248.518125\" width=\"375.2875pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <defs>\n  <style type=\"text/css\">\n*{stroke-linecap:butt;stroke-linejoin:round;}\n  </style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 248.518125 \nL 375.2875 248.518125 \nL 375.2875 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 33.2875 224.64 \nL 368.0875 224.64 \nL 368.0875 7.2 \nL 33.2875 7.2 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path clip-path=\"url(#pf5621fc07d)\" d=\"M 48.505682 224.64 \nL 78.942045 224.64 \nL 78.942045 161.040642 \nL 48.505682 161.040642 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path clip-path=\"url(#pf5621fc07d)\" d=\"M 78.942045 224.64 \nL 109.378409 224.64 \nL 109.378409 224.64 \nL 78.942045 224.64 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path clip-path=\"url(#pf5621fc07d)\" d=\"M 109.378409 224.64 \nL 139.814773 224.64 \nL 139.814773 196.201263 \nL 109.378409 196.201263 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path clip-path=\"url(#pf5621fc07d)\" d=\"M 139.814773 224.64 \nL 170.251136 224.64 \nL 170.251136 224.64 \nL 139.814773 224.64 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_7\">\n    <path clip-path=\"url(#pf5621fc07d)\" d=\"M 170.251136 224.64 \nL 200.6875 224.64 \nL 200.6875 224.64 \nL 170.251136 224.64 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_8\">\n    <path clip-path=\"url(#pf5621fc07d)\" d=\"M 200.6875 224.64 \nL 231.123864 224.64 \nL 231.123864 185.084302 \nL 200.6875 185.084302 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_9\">\n    <path clip-path=\"url(#pf5621fc07d)\" d=\"M 231.123864 224.64 \nL 261.560227 224.64 \nL 261.560227 224.64 \nL 231.123864 224.64 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_10\">\n    <path clip-path=\"url(#pf5621fc07d)\" d=\"M 261.560227 224.64 \nL 291.996591 224.64 \nL 291.996591 149.406613 \nL 261.560227 149.406613 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_11\">\n    <path clip-path=\"url(#pf5621fc07d)\" d=\"M 291.996591 224.64 \nL 322.432955 224.64 \nL 322.432955 224.64 \nL 291.996591 224.64 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_12\">\n    <path clip-path=\"url(#pf5621fc07d)\" d=\"M 322.432955 224.64 \nL 352.869318 224.64 \nL 352.869318 17.554286 \nL 322.432955 17.554286 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"m4a17c72e1a\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"48.505682\" xlink:href=\"#m4a17c72e1a\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 1.0 -->\n      <defs>\n       <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n       <path d=\"M 10.6875 12.40625 \nL 21 12.40625 \nL 21 0 \nL 10.6875 0 \nz\n\" id=\"DejaVuSans-46\"/>\n       <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n      </defs>\n      <g transform=\"translate(40.554119 239.238438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"86.551136\" xlink:href=\"#m4a17c72e1a\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 1.5 -->\n      <defs>\n       <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n      </defs>\n      <g transform=\"translate(78.599574 239.238438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"124.596591\" xlink:href=\"#m4a17c72e1a\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 2.0 -->\n      <defs>\n       <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n      </defs>\n      <g transform=\"translate(116.645028 239.238438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"162.642045\" xlink:href=\"#m4a17c72e1a\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 2.5 -->\n      <g transform=\"translate(154.690483 239.238438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"200.6875\" xlink:href=\"#m4a17c72e1a\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 3.0 -->\n      <defs>\n       <path d=\"M 40.578125 39.3125 \nQ 47.65625 37.796875 51.625 33 \nQ 55.609375 28.21875 55.609375 21.1875 \nQ 55.609375 10.40625 48.1875 4.484375 \nQ 40.765625 -1.421875 27.09375 -1.421875 \nQ 22.515625 -1.421875 17.65625 -0.515625 \nQ 12.796875 0.390625 7.625 2.203125 \nL 7.625 11.71875 \nQ 11.71875 9.328125 16.59375 8.109375 \nQ 21.484375 6.890625 26.8125 6.890625 \nQ 36.078125 6.890625 40.9375 10.546875 \nQ 45.796875 14.203125 45.796875 21.1875 \nQ 45.796875 27.640625 41.28125 31.265625 \nQ 36.765625 34.90625 28.71875 34.90625 \nL 20.21875 34.90625 \nL 20.21875 43.015625 \nL 29.109375 43.015625 \nQ 36.375 43.015625 40.234375 45.921875 \nQ 44.09375 48.828125 44.09375 54.296875 \nQ 44.09375 59.90625 40.109375 62.90625 \nQ 36.140625 65.921875 28.71875 65.921875 \nQ 24.65625 65.921875 20.015625 65.03125 \nQ 15.375 64.15625 9.8125 62.3125 \nL 9.8125 71.09375 \nQ 15.4375 72.65625 20.34375 73.4375 \nQ 25.25 74.21875 29.59375 74.21875 \nQ 40.828125 74.21875 47.359375 69.109375 \nQ 53.90625 64.015625 53.90625 55.328125 \nQ 53.90625 49.265625 50.4375 45.09375 \nQ 46.96875 40.921875 40.578125 39.3125 \nz\n\" id=\"DejaVuSans-51\"/>\n      </defs>\n      <g transform=\"translate(192.735938 239.238438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"238.732955\" xlink:href=\"#m4a17c72e1a\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 3.5 -->\n      <g transform=\"translate(230.781392 239.238438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_7\">\n     <g id=\"line2d_7\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"276.778409\" xlink:href=\"#m4a17c72e1a\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 4.0 -->\n      <defs>\n       <path d=\"M 37.796875 64.3125 \nL 12.890625 25.390625 \nL 37.796875 25.390625 \nz\nM 35.203125 72.90625 \nL 47.609375 72.90625 \nL 47.609375 25.390625 \nL 58.015625 25.390625 \nL 58.015625 17.1875 \nL 47.609375 17.1875 \nL 47.609375 0 \nL 37.796875 0 \nL 37.796875 17.1875 \nL 4.890625 17.1875 \nL 4.890625 26.703125 \nz\n\" id=\"DejaVuSans-52\"/>\n      </defs>\n      <g transform=\"translate(268.826847 239.238438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-52\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_8\">\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"314.823864\" xlink:href=\"#m4a17c72e1a\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 4.5 -->\n      <g transform=\"translate(306.872301 239.238438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-52\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_9\">\n     <g id=\"line2d_9\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"352.869318\" xlink:href=\"#m4a17c72e1a\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 5.0 -->\n      <g transform=\"translate(344.917756 239.238438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_10\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"mfb94660681\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#mfb94660681\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 0 -->\n      <g transform=\"translate(19.925 228.439219)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_11\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#mfb94660681\" y=\"198.786602\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 100 -->\n      <g transform=\"translate(7.2 202.585821)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#mfb94660681\" y=\"172.933205\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 200 -->\n      <g transform=\"translate(7.2 176.732424)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_13\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#mfb94660681\" y=\"147.079807\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 300 -->\n      <g transform=\"translate(7.2 150.879026)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_14\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#mfb94660681\" y=\"121.22641\"/>\n      </g>\n     </g>\n     <g id=\"text_14\">\n      <!-- 400 -->\n      <g transform=\"translate(7.2 125.025629)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-52\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_15\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#mfb94660681\" y=\"95.373012\"/>\n      </g>\n     </g>\n     <g id=\"text_15\">\n      <!-- 500 -->\n      <g transform=\"translate(7.2 99.172231)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_7\">\n     <g id=\"line2d_16\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#mfb94660681\" y=\"69.519615\"/>\n      </g>\n     </g>\n     <g id=\"text_16\">\n      <!-- 600 -->\n      <defs>\n       <path d=\"M 33.015625 40.375 \nQ 26.375 40.375 22.484375 35.828125 \nQ 18.609375 31.296875 18.609375 23.390625 \nQ 18.609375 15.53125 22.484375 10.953125 \nQ 26.375 6.390625 33.015625 6.390625 \nQ 39.65625 6.390625 43.53125 10.953125 \nQ 47.40625 15.53125 47.40625 23.390625 \nQ 47.40625 31.296875 43.53125 35.828125 \nQ 39.65625 40.375 33.015625 40.375 \nz\nM 52.59375 71.296875 \nL 52.59375 62.3125 \nQ 48.875 64.0625 45.09375 64.984375 \nQ 41.3125 65.921875 37.59375 65.921875 \nQ 27.828125 65.921875 22.671875 59.328125 \nQ 17.53125 52.734375 16.796875 39.40625 \nQ 19.671875 43.65625 24.015625 45.921875 \nQ 28.375 48.1875 33.59375 48.1875 \nQ 44.578125 48.1875 50.953125 41.515625 \nQ 57.328125 34.859375 57.328125 23.390625 \nQ 57.328125 12.15625 50.6875 5.359375 \nQ 44.046875 -1.421875 33.015625 -1.421875 \nQ 20.359375 -1.421875 13.671875 8.265625 \nQ 6.984375 17.96875 6.984375 36.375 \nQ 6.984375 53.65625 15.1875 63.9375 \nQ 23.390625 74.21875 37.203125 74.21875 \nQ 40.921875 74.21875 44.703125 73.484375 \nQ 48.484375 72.75 52.59375 71.296875 \nz\n\" id=\"DejaVuSans-54\"/>\n      </defs>\n      <g transform=\"translate(7.2 73.318834)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-54\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_8\">\n     <g id=\"line2d_17\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#mfb94660681\" y=\"43.666217\"/>\n      </g>\n     </g>\n     <g id=\"text_17\">\n      <!-- 700 -->\n      <defs>\n       <path d=\"M 8.203125 72.90625 \nL 55.078125 72.90625 \nL 55.078125 68.703125 \nL 28.609375 0 \nL 18.3125 0 \nL 43.21875 64.59375 \nL 8.203125 64.59375 \nz\n\" id=\"DejaVuSans-55\"/>\n      </defs>\n      <g transform=\"translate(7.2 47.465436)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-55\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_9\">\n     <g id=\"line2d_18\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#mfb94660681\" y=\"17.81282\"/>\n      </g>\n     </g>\n     <g id=\"text_18\">\n      <!-- 800 -->\n      <defs>\n       <path d=\"M 31.78125 34.625 \nQ 24.75 34.625 20.71875 30.859375 \nQ 16.703125 27.09375 16.703125 20.515625 \nQ 16.703125 13.921875 20.71875 10.15625 \nQ 24.75 6.390625 31.78125 6.390625 \nQ 38.8125 6.390625 42.859375 10.171875 \nQ 46.921875 13.96875 46.921875 20.515625 \nQ 46.921875 27.09375 42.890625 30.859375 \nQ 38.875 34.625 31.78125 34.625 \nz\nM 21.921875 38.8125 \nQ 15.578125 40.375 12.03125 44.71875 \nQ 8.5 49.078125 8.5 55.328125 \nQ 8.5 64.0625 14.71875 69.140625 \nQ 20.953125 74.21875 31.78125 74.21875 \nQ 42.671875 74.21875 48.875 69.140625 \nQ 55.078125 64.0625 55.078125 55.328125 \nQ 55.078125 49.078125 51.53125 44.71875 \nQ 48 40.375 41.703125 38.8125 \nQ 48.828125 37.15625 52.796875 32.3125 \nQ 56.78125 27.484375 56.78125 20.515625 \nQ 56.78125 9.90625 50.3125 4.234375 \nQ 43.84375 -1.421875 31.78125 -1.421875 \nQ 19.734375 -1.421875 13.25 4.234375 \nQ 6.78125 9.90625 6.78125 20.515625 \nQ 6.78125 27.484375 10.78125 32.3125 \nQ 14.796875 37.15625 21.921875 38.8125 \nz\nM 18.3125 54.390625 \nQ 18.3125 48.734375 21.84375 45.5625 \nQ 25.390625 42.390625 31.78125 42.390625 \nQ 38.140625 42.390625 41.71875 45.5625 \nQ 45.3125 48.734375 45.3125 54.390625 \nQ 45.3125 60.0625 41.71875 63.234375 \nQ 38.140625 66.40625 31.78125 66.40625 \nQ 25.390625 66.40625 21.84375 63.234375 \nQ 18.3125 60.0625 18.3125 54.390625 \nz\n\" id=\"DejaVuSans-56\"/>\n      </defs>\n      <g transform=\"translate(7.2 21.612038)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-56\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"patch_13\">\n    <path d=\"M 33.2875 224.64 \nL 33.2875 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_14\">\n    <path d=\"M 368.0875 224.64 \nL 368.0875 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_15\">\n    <path d=\"M 33.2875 224.64 \nL 368.0875 224.64 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_16\">\n    <path d=\"M 33.2875 7.2 \nL 368.0875 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"pf5621fc07d\">\n   <rect height=\"217.44\" width=\"334.8\" x=\"33.2875\" y=\"7.2\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAS8klEQVR4nO3dfYzl1X3f8fcnLNgOdlkeplu6u3SQvHJErRpvRnQtIstl64gHi0UqRlitWaONtg+ksUulZJM/aqXqH1iqQkxbEa2MmyX1A5SYsMHENVqIokqFZMAEDNj1hEJ2V8COMayTECfZ5Ns/7tn4Mszu3Nm588Dx+yVd3fM75/zm970H5rO/+d2nVBWSpL782GoXIEkaP8NdkjpkuEtShwx3SeqQ4S5JHVq32gUAnHfeeTU5ObnaZUjSW8pjjz323aqamG9sTYT75OQk09PTq12GJL2lJHnhRGNelpGkDhnuktQhw12SOmS4S1KHDHdJ6pDhLkkdGinck/y7JE8n+WaSLyV5e5ILkzyaZCbJXUnOaHPf1rZn2vjkcj4ASdKbLRjuSTYCPwdMVdV7gdOA64HPALdW1buBV4FdbZddwKut/9Y2T5K0gka9LLMOeEeSdcCPAy8ClwH3tPF9wDWtvaNt08a3J8l4ypUkjWLBd6hW1eEk/xn4Y+DPga8DjwGvVdWxNu0QsLG1NwIH277HkhwFzgW+O/xzk+wGdgNccMEFS38kknSKJvd8ddWO/fwtVy3Lzx3lsszZDM7GLwT+PnAmcPlSD1xVe6tqqqqmJibm/WgESdIpGuWyzD8F/l9VzVbVXwFfAS4F1rfLNACbgMOtfRjYDNDGzwJeGWvVkqSTGiXc/xjYluTH27Xz7cAzwMPAtW3OTuC+1t7ftmnjD5Vf1CpJK2rBcK+qRxk8Mfo48FTbZy/wC8DNSWYYXFO/o+1yB3Bu678Z2LMMdUuSTmKkj/ytqk8Dn57T/RxwyTxzfwB8dOmlSZJOle9QlaQOGe6S1CHDXZI6ZLhLUocMd0nqkOEuSR0y3CWpQ4a7JHXIcJekDhnuktQhw12SOmS4S1KHDHdJ6pDhLkkdMtwlqUOGuyR1yHCXpA4tGO5J3pPkiaHb95N8Ksk5SR5M8p12f3abnyS3JZlJ8mSSrcv/MCRJw0b5DtVvV9XFVXUx8JPA68C9DL4b9UBVbQEO8MPvSr0C2NJuu4Hbl6NwSdKJLfayzHbgj6rqBWAHsK/17wOuae0dwJ018AiwPsn5Y6lWkjSSxYb79cCXWntDVb3Y2i8BG1p7I3BwaJ9Dre8NkuxOMp1kenZ2dpFlSJJOZuRwT3IGcDXwP+eOVVUBtZgDV9XeqpqqqqmJiYnF7CpJWsBiztyvAB6vqpfb9svHL7e0+yOt/zCweWi/Ta1PkrRCFhPuH+OHl2QA9gM7W3sncN9Q/w3tVTPbgKNDl28kSStg3SiTkpwJfBj4l0PdtwB3J9kFvABc1/ofAK4EZhi8subGsVUrSRrJSOFeVX8GnDun7xUGr56ZO7eAm8ZSnSTplPgOVUnqkOEuSR0y3CWpQ4a7JHXIcJekDhnuktQhw12SOmS4S1KHDHdJ6pDhLkkdMtwlqUOGuyR1yHCXpA4Z7pLUIcNdkjpkuEtShwx3SerQSOGeZH2Se5J8K8mzST6Q5JwkDyb5Trs/u81NktuSzCR5MsnW5X0IkqS5Rj1z/yzwtar6CeB9wLPAHuBAVW0BDrRtgCuALe22G7h9rBVLkha0YLgnOQv4IHAHQFX9ZVW9BuwA9rVp+4BrWnsHcGcNPAKsT3L+2CuXJJ3QKGfuFwKzwH9P8o0kn0tyJrChql5sc14CNrT2RuDg0P6HWt8bJNmdZDrJ9Ozs7Kk/AknSm4wS7uuArcDtVfV+4M/44SUYAKqqgFrMgatqb1VNVdXUxMTEYnaVJC1glHA/BByqqkfb9j0Mwv7l45db2v2RNn4Y2Dy0/6bWJ0laIQuGe1W9BBxM8p7WtR14BtgP7Gx9O4H7Wns/cEN71cw24OjQ5RtJ0gpYN+K8fwt8IckZwHPAjQz+Ybg7yS7gBeC6NvcB4EpgBni9zZUkraCRwr2qngCm5hnaPs/cAm5aYl2SpCXwHaqS1CHDXZI6ZLhLUocMd0nqkOEuSR0y3CWpQ4a7JHXIcJekDhnuktQhw12SOmS4S1KHDHdJ6pDhLkkdMtwlqUOGuyR1yHCXpA6NFO5Jnk/yVJInkky3vnOSPJjkO+3+7NafJLclmUnyZJKty/kAJElvtpgz939SVRdX1fFvZNoDHKiqLcCBtg1wBbCl3XYDt4+rWEnSaJZyWWYHsK+19wHXDPXfWQOPAOuTnL+E40iSFmnUcC/g60keS7K79W2oqhdb+yVgQ2tvBA4O7Xuo9UmSVshIX5AN/FRVHU7yd4EHk3xreLCqKkkt5sDtH4ndABdccMFidpUkLWCkM/eqOtzujwD3ApcALx+/3NLuj7Tph4HNQ7tvan1zf+beqpqqqqmJiYlTfwSSpDdZMNyTnJnkXcfbwE8D3wT2AzvbtJ3Afa29H7ihvWpmG3B06PKNJGkFjHJZZgNwb5Lj879YVV9L8gfA3Ul2AS8A17X5DwBXAjPA68CNY69aknRSC4Z7VT0HvG+e/leA7fP0F3DTWKqTJJ0S36EqSR0y3CWpQ4a7JHXIcJekDhnuktQhw12SOmS4S1KHDHdJ6pDhLkkdMtwlqUOGuyR1yHCXpA4Z7pLUIcNdkjpkuEtShwx3SeqQ4S5JHRo53JOcluQbSe5v2xcmeTTJTJK7kpzR+t/Wtmfa+OTylC5JOpHFnLl/Enh2aPszwK1V9W7gVWBX698FvNr6b23zJEkraKRwT7IJuAr4XNsOcBlwT5uyD7imtXe0bdr49jZfkrRCRj1z/1Xg54G/advnAq9V1bG2fQjY2NobgYMAbfxom/8GSXYnmU4yPTs7e4rlS5Lms2C4J/kIcKSqHhvngatqb1VNVdXUxMTEOH+0JP3IWzfCnEuBq5NcCbwd+DvAZ4H1Sda1s/NNwOE2/zCwGTiUZB1wFvDK2CuXJJ3QgmfuVfWLVbWpqiaB64GHquqfAw8D17ZpO4H7Wnt/26aNP1RVNdaqJUkntZTXuf8CcHOSGQbX1O9o/XcA57b+m4E9SytRkrRYo1yW+VtV9bvA77b2c8Al88z5AfDRMdQmSTpFvkNVkjpkuEtShwx3SeqQ4S5JHTLcJalDhrskdchwl6QOGe6S1CHDXZI6ZLhLUocMd0nqkOEuSR0y3CWpQ4a7JHXIcJekDhnuktQhw12SOrRguCd5e5LfT/KHSZ5O8sut/8IkjyaZSXJXkjNa/9va9kwbn1zehyBJmmuUM/e/AC6rqvcBFwOXJ9kGfAa4tareDbwK7GrzdwGvtv5b2zxJ0gpaMNxr4E/b5untVsBlwD2tfx9wTWvvaNu08e1JMraKJUkLGumae5LTkjwBHAEeBP4IeK2qjrUph4CNrb0ROAjQxo8C587zM3cnmU4yPTs7u7RHIUl6g5HCvar+uqouBjYBlwA/sdQDV9XeqpqqqqmJiYml/jhJ0pBFvVqmql4DHgY+AKxPsq4NbQIOt/ZhYDNAGz8LeGUs1UqSRrJuoQlJJoC/qqrXkrwD+DCDJ0kfBq4FvgzsBO5ru+xv2/+njT9UVbUMtUtaBpN7vrpqx37+lqtW7di9WTDcgfOBfUlOY3Cmf3dV3Z/kGeDLSf4T8A3gjjb/DuA3kswA3wOuX4a6JUknsWC4V9WTwPvn6X+OwfX3uf0/AD46luokSafEd6hKUocMd0nqkOEuSR0y3CWpQ4a7JHXIcJekDhnuktQhw12SOjTKO1TXNN8qLUlv5pm7JHXIcJekDhnuktQhw12SOmS4S1KHDHdJ6pDhLkkdMtwlqUMLhnuSzUkeTvJMkqeTfLL1n5PkwSTfafdnt/4kuS3JTJInk2xd7gchSXqjUc7cjwH/vqouArYBNyW5CNgDHKiqLcCBtg1wBbCl3XYDt4+9aknSSS0Y7lX1YlU93tp/AjwLbAR2APvatH3ANa29A7izBh4B1ic5f+yVS5JOaFHX3JNMMviy7EeBDVX1Yht6CdjQ2huBg0O7HWp9c3/W7iTTSaZnZ2cXWbYk6WRGDvck7wR+E/hUVX1/eKyqCqjFHLiq9lbVVFVNTUxMLGZXSdICRgr3JKczCPYvVNVXWvfLxy+3tPsjrf8wsHlo902tT5K0QkZ5tUyAO4Bnq+pXhob2Aztbeydw31D/De1VM9uAo0OXbyRJK2CUz3O/FPg48FSSJ1rfLwG3AHcn2QW8AFzXxh4ArgRmgNeBG8dasSRpQQuGe1X9byAnGN4+z/wCblpiXZKkJfAdqpLUIcNdkjpkuEtShwx3SeqQ4S5JHTLcJalDo7zOXfqRNbnnq6t27OdvuWrVjq23Ps/cJalDhrskdchwl6QOGe6S1CHDXZI6ZLhLUocMd0nqkOEuSR0y3CWpQ4a7JHVowY8fSPJ54CPAkap6b+s7B7gLmASeB66rqlfb961+lsHX7L0OfKKqHl+e0n90+ZZ4SQsZ5cz914HL5/TtAQ5U1RbgQNsGuALY0m67gdvHU6YkaTEWDPeq+j3ge3O6dwD7WnsfcM1Q/5018AiwPsn54ypWkjSaU73mvqGqXmztl4ANrb0RODg071Dre5Mku5NMJ5menZ09xTIkSfNZ8hOqVVVAncJ+e6tqqqqmJiYmllqGJGnIqYb7y8cvt7T7I63/MLB5aN6m1idJWkGnGu77gZ2tvRO4b6j/hgxsA44OXb6RJK2QUV4K+SXgQ8B5SQ4BnwZuAe5Osgt4AbiuTX+AwcsgZxi8FPLGZahZkrSABcO9qj52gqHt88wt4KalFiVJWhrfoSpJHTLcJalDhrskdchwl6QOGe6S1CHDXZI6ZLhLUocMd0nqkOEuSR0y3CWpQ4a7JHXIcJekDhnuktQhw12SOmS4S1KHDHdJ6pDhLkkdWpZwT3J5km8nmUmyZzmOIUk6sbGHe5LTgP8GXAFcBHwsyUXjPo4k6cSW48z9EmCmqp6rqr8EvgzsWIbjSJJOIIPvtB7jD0yuBS6vqp9p2x8H/nFV/eycebuB3W3zPcC3T/GQ5wHfPcV9l5N1LY51Ld5arc26Fmcpdf2DqpqYb2DdqdezNFW1F9i71J+TZLqqpsZQ0lhZ1+JY1+Kt1dqsa3GWq67luCxzGNg8tL2p9UmSVshyhPsfAFuSXJjkDOB6YP8yHEeSdAJjvyxTVceS/Czwv4DTgM9X1dPjPs6QJV/aWSbWtTjWtXhrtTbrWpxlqWvsT6hKklaf71CVpA4Z7pLUobdEuCf5fJIjSb55gvEkua193MGTSbaukbo+lORokifa7T+sUF2bkzyc5JkkTyf55DxzVnzNRqxrxdcsyduT/H6SP2x1/fI8c96W5K62Xo8mmVwjdX0iyezQev3Mctc1dOzTknwjyf3zjK34eo1Y12qu1/NJnmrHnZ5nfLy/k1W15m/AB4GtwDdPMH4l8DtAgG3Ao2ukrg8B96/Cep0PbG3tdwH/F7hotddsxLpWfM3aGryztU8HHgW2zZnzb4Bfa+3rgbvWSF2fAP7rSv8/1o59M/DF+f57rcZ6jVjXaq7X88B5Jxkf6+/kW+LMvap+D/jeSabsAO6sgUeA9UnOXwN1rYqqerGqHm/tPwGeBTbOmbbiazZiXSuurcGfts3T223uKw12APta+x5ge5KsgbpWRZJNwFXA504wZcXXa8S61rKx/k6+JcJ9BBuBg0Pbh1gDodF8oP1Z/TtJ/uFKH7z9Ofx+Bmd9w1Z1zU5SF6zCmrU/5Z8AjgAPVtUJ16uqjgFHgXPXQF0A/6z9GX9Pks3zjC+HXwV+HvibE4yvynqNUBesznrB4B/mryd5LIOPX5lrrL+TvYT7WvU4g89+eB/wX4DfWsmDJ3kn8JvAp6rq+yt57JNZoK5VWbOq+uuqupjBO6ovSfLelTjuQkao67eByar6R8CD/PBsedkk+QhwpKoeW+5jLcaIda34eg35qarayuATc29K8sHlPFgv4b4mP/Kgqr5//M/qqnoAOD3JeStx7CSnMwjQL1TVV+aZsiprtlBdq7lm7ZivAQ8Dl88Z+tv1SrIOOAt4ZbXrqqpXquov2ubngJ9cgXIuBa5O8jyDT329LMn/mDNnNdZrwbpWab2OH/twuz8C3MvgE3SHjfV3spdw3w/c0J5t3gYcraoXV7uoJH/v+HXGJJcwWO9lD4R2zDuAZ6vqV04wbcXXbJS6VmPNkkwkWd/a7wA+DHxrzrT9wM7WvhZ4qNqzYKtZ15xrslczeB5jWVXVL1bVpqqaZPBk6UNV9S/mTFvx9RqlrtVYr3bcM5O863gb+Glg7qvsxvo7uWqfCrkYSb7E4FUU5yU5BHyawZNLVNWvAQ8weKZ5BngduHGN1HUt8K+THAP+HLh+uf8Hby4FPg481a7XAvwScMFQbauxZqPUtRprdj6wL4Mvmvkx4O6quj/JfwSmq2o/g3+UfiPJDIMn0a9f5ppGrevnklwNHGt1fWIF6prXGlivUeparfXaANzbzlvWAV+sqq8l+VewPL+TfvyAJHWol8sykqQhhrskdchwl6QOGe6S1CHDXZI6ZLhLUocMd0nq0P8HZdyybxrVpRoAAAAASUVORK5CYII=\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "val.overall.hist(\n",
    "    grid=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "5    862\n4    282\n1    201\n3    153\n2    100\nName: overall, dtype: int64"
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "test.overall.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<matplotlib.axes._subplots.AxesSubplot at 0x7f49df4589d0>"
     },
     "metadata": {},
     "execution_count": 24
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"248.518125pt\" version=\"1.1\" viewBox=\"0 0 375.2875 248.518125\" width=\"375.2875pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <defs>\n  <style type=\"text/css\">\n*{stroke-linecap:butt;stroke-linejoin:round;}\n  </style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 248.518125 \nL 375.2875 248.518125 \nL 375.2875 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 33.2875 224.64 \nL 368.0875 224.64 \nL 368.0875 7.2 \nL 33.2875 7.2 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path clip-path=\"url(#pd6cd881001)\" d=\"M 48.505682 224.64 \nL 78.942045 224.64 \nL 78.942045 176.352032 \nL 48.505682 176.352032 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path clip-path=\"url(#pd6cd881001)\" d=\"M 78.942045 224.64 \nL 109.378409 224.64 \nL 109.378409 224.64 \nL 78.942045 224.64 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path clip-path=\"url(#pd6cd881001)\" d=\"M 109.378409 224.64 \nL 139.814773 224.64 \nL 139.814773 200.616135 \nL 109.378409 200.616135 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path clip-path=\"url(#pd6cd881001)\" d=\"M 139.814773 224.64 \nL 170.251136 224.64 \nL 170.251136 224.64 \nL 139.814773 224.64 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_7\">\n    <path clip-path=\"url(#pd6cd881001)\" d=\"M 170.251136 224.64 \nL 200.6875 224.64 \nL 200.6875 224.64 \nL 170.251136 224.64 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_8\">\n    <path clip-path=\"url(#pd6cd881001)\" d=\"M 200.6875 224.64 \nL 231.123864 224.64 \nL 231.123864 187.883487 \nL 200.6875 187.883487 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_9\">\n    <path clip-path=\"url(#pd6cd881001)\" d=\"M 231.123864 224.64 \nL 261.560227 224.64 \nL 261.560227 224.64 \nL 231.123864 224.64 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_10\">\n    <path clip-path=\"url(#pd6cd881001)\" d=\"M 261.560227 224.64 \nL 291.996591 224.64 \nL 291.996591 156.892701 \nL 261.560227 156.892701 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_11\">\n    <path clip-path=\"url(#pd6cd881001)\" d=\"M 291.996591 224.64 \nL 322.432955 224.64 \nL 322.432955 224.64 \nL 291.996591 224.64 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_12\">\n    <path clip-path=\"url(#pd6cd881001)\" d=\"M 322.432955 224.64 \nL 352.869318 224.64 \nL 352.869318 17.554286 \nL 322.432955 17.554286 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"me8c7a2f611\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"48.505682\" xlink:href=\"#me8c7a2f611\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 1.0 -->\n      <defs>\n       <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n       <path d=\"M 10.6875 12.40625 \nL 21 12.40625 \nL 21 0 \nL 10.6875 0 \nz\n\" id=\"DejaVuSans-46\"/>\n       <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n      </defs>\n      <g transform=\"translate(40.554119 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"86.551136\" xlink:href=\"#me8c7a2f611\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 1.5 -->\n      <defs>\n       <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n      </defs>\n      <g transform=\"translate(78.599574 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"124.596591\" xlink:href=\"#me8c7a2f611\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 2.0 -->\n      <defs>\n       <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n      </defs>\n      <g transform=\"translate(116.645028 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"162.642045\" xlink:href=\"#me8c7a2f611\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 2.5 -->\n      <g transform=\"translate(154.690483 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"200.6875\" xlink:href=\"#me8c7a2f611\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 3.0 -->\n      <defs>\n       <path d=\"M 40.578125 39.3125 \nQ 47.65625 37.796875 51.625 33 \nQ 55.609375 28.21875 55.609375 21.1875 \nQ 55.609375 10.40625 48.1875 4.484375 \nQ 40.765625 -1.421875 27.09375 -1.421875 \nQ 22.515625 -1.421875 17.65625 -0.515625 \nQ 12.796875 0.390625 7.625 2.203125 \nL 7.625 11.71875 \nQ 11.71875 9.328125 16.59375 8.109375 \nQ 21.484375 6.890625 26.8125 6.890625 \nQ 36.078125 6.890625 40.9375 10.546875 \nQ 45.796875 14.203125 45.796875 21.1875 \nQ 45.796875 27.640625 41.28125 31.265625 \nQ 36.765625 34.90625 28.71875 34.90625 \nL 20.21875 34.90625 \nL 20.21875 43.015625 \nL 29.109375 43.015625 \nQ 36.375 43.015625 40.234375 45.921875 \nQ 44.09375 48.828125 44.09375 54.296875 \nQ 44.09375 59.90625 40.109375 62.90625 \nQ 36.140625 65.921875 28.71875 65.921875 \nQ 24.65625 65.921875 20.015625 65.03125 \nQ 15.375 64.15625 9.8125 62.3125 \nL 9.8125 71.09375 \nQ 15.4375 72.65625 20.34375 73.4375 \nQ 25.25 74.21875 29.59375 74.21875 \nQ 40.828125 74.21875 47.359375 69.109375 \nQ 53.90625 64.015625 53.90625 55.328125 \nQ 53.90625 49.265625 50.4375 45.09375 \nQ 46.96875 40.921875 40.578125 39.3125 \nz\n\" id=\"DejaVuSans-51\"/>\n      </defs>\n      <g transform=\"translate(192.735938 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"238.732955\" xlink:href=\"#me8c7a2f611\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 3.5 -->\n      <g transform=\"translate(230.781392 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_7\">\n     <g id=\"line2d_7\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"276.778409\" xlink:href=\"#me8c7a2f611\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 4.0 -->\n      <defs>\n       <path d=\"M 37.796875 64.3125 \nL 12.890625 25.390625 \nL 37.796875 25.390625 \nz\nM 35.203125 72.90625 \nL 47.609375 72.90625 \nL 47.609375 25.390625 \nL 58.015625 25.390625 \nL 58.015625 17.1875 \nL 47.609375 17.1875 \nL 47.609375 0 \nL 37.796875 0 \nL 37.796875 17.1875 \nL 4.890625 17.1875 \nL 4.890625 26.703125 \nz\n\" id=\"DejaVuSans-52\"/>\n      </defs>\n      <g transform=\"translate(268.826847 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-52\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_8\">\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"314.823864\" xlink:href=\"#me8c7a2f611\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 4.5 -->\n      <g transform=\"translate(306.872301 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-52\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_9\">\n     <g id=\"line2d_9\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"352.869318\" xlink:href=\"#me8c7a2f611\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 5.0 -->\n      <g transform=\"translate(344.917756 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_10\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"md96a391c3a\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#md96a391c3a\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 0 -->\n      <g transform=\"translate(19.925 228.439219)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_11\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#md96a391c3a\" y=\"176.59227\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 200 -->\n      <g transform=\"translate(7.2 180.391489)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#md96a391c3a\" y=\"128.544541\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 400 -->\n      <g transform=\"translate(7.2 132.34376)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-52\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_13\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#md96a391c3a\" y=\"80.496811\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 600 -->\n      <defs>\n       <path d=\"M 33.015625 40.375 \nQ 26.375 40.375 22.484375 35.828125 \nQ 18.609375 31.296875 18.609375 23.390625 \nQ 18.609375 15.53125 22.484375 10.953125 \nQ 26.375 6.390625 33.015625 6.390625 \nQ 39.65625 6.390625 43.53125 10.953125 \nQ 47.40625 15.53125 47.40625 23.390625 \nQ 47.40625 31.296875 43.53125 35.828125 \nQ 39.65625 40.375 33.015625 40.375 \nz\nM 52.59375 71.296875 \nL 52.59375 62.3125 \nQ 48.875 64.0625 45.09375 64.984375 \nQ 41.3125 65.921875 37.59375 65.921875 \nQ 27.828125 65.921875 22.671875 59.328125 \nQ 17.53125 52.734375 16.796875 39.40625 \nQ 19.671875 43.65625 24.015625 45.921875 \nQ 28.375 48.1875 33.59375 48.1875 \nQ 44.578125 48.1875 50.953125 41.515625 \nQ 57.328125 34.859375 57.328125 23.390625 \nQ 57.328125 12.15625 50.6875 5.359375 \nQ 44.046875 -1.421875 33.015625 -1.421875 \nQ 20.359375 -1.421875 13.671875 8.265625 \nQ 6.984375 17.96875 6.984375 36.375 \nQ 6.984375 53.65625 15.1875 63.9375 \nQ 23.390625 74.21875 37.203125 74.21875 \nQ 40.921875 74.21875 44.703125 73.484375 \nQ 48.484375 72.75 52.59375 71.296875 \nz\n\" id=\"DejaVuSans-54\"/>\n      </defs>\n      <g transform=\"translate(7.2 84.29603)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-54\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_14\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#md96a391c3a\" y=\"32.449082\"/>\n      </g>\n     </g>\n     <g id=\"text_14\">\n      <!-- 800 -->\n      <defs>\n       <path d=\"M 31.78125 34.625 \nQ 24.75 34.625 20.71875 30.859375 \nQ 16.703125 27.09375 16.703125 20.515625 \nQ 16.703125 13.921875 20.71875 10.15625 \nQ 24.75 6.390625 31.78125 6.390625 \nQ 38.8125 6.390625 42.859375 10.171875 \nQ 46.921875 13.96875 46.921875 20.515625 \nQ 46.921875 27.09375 42.890625 30.859375 \nQ 38.875 34.625 31.78125 34.625 \nz\nM 21.921875 38.8125 \nQ 15.578125 40.375 12.03125 44.71875 \nQ 8.5 49.078125 8.5 55.328125 \nQ 8.5 64.0625 14.71875 69.140625 \nQ 20.953125 74.21875 31.78125 74.21875 \nQ 42.671875 74.21875 48.875 69.140625 \nQ 55.078125 64.0625 55.078125 55.328125 \nQ 55.078125 49.078125 51.53125 44.71875 \nQ 48 40.375 41.703125 38.8125 \nQ 48.828125 37.15625 52.796875 32.3125 \nQ 56.78125 27.484375 56.78125 20.515625 \nQ 56.78125 9.90625 50.3125 4.234375 \nQ 43.84375 -1.421875 31.78125 -1.421875 \nQ 19.734375 -1.421875 13.25 4.234375 \nQ 6.78125 9.90625 6.78125 20.515625 \nQ 6.78125 27.484375 10.78125 32.3125 \nQ 14.796875 37.15625 21.921875 38.8125 \nz\nM 18.3125 54.390625 \nQ 18.3125 48.734375 21.84375 45.5625 \nQ 25.390625 42.390625 31.78125 42.390625 \nQ 38.140625 42.390625 41.71875 45.5625 \nQ 45.3125 48.734375 45.3125 54.390625 \nQ 45.3125 60.0625 41.71875 63.234375 \nQ 38.140625 66.40625 31.78125 66.40625 \nQ 25.390625 66.40625 21.84375 63.234375 \nQ 18.3125 60.0625 18.3125 54.390625 \nz\n\" id=\"DejaVuSans-56\"/>\n      </defs>\n      <g transform=\"translate(7.2 36.248301)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-56\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"patch_13\">\n    <path d=\"M 33.2875 224.64 \nL 33.2875 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_14\">\n    <path d=\"M 368.0875 224.64 \nL 368.0875 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_15\">\n    <path d=\"M 33.2875 224.64 \nL 368.0875 224.64 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_16\">\n    <path d=\"M 33.2875 7.2 \nL 368.0875 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"pd6cd881001\">\n   <rect height=\"217.44\" width=\"334.8\" x=\"33.2875\" y=\"7.2\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "test.overall.hist(grid=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<matplotlib.axes._subplots.AxesSubplot at 0x7f49df36a5b0>"
     },
     "metadata": {},
     "execution_count": 25
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"248.518125pt\" version=\"1.1\" viewBox=\"0 0 381.65 248.518125\" width=\"381.65pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <defs>\n  <style type=\"text/css\">\n*{stroke-linecap:butt;stroke-linejoin:round;}\n  </style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M -0 248.518125 \nL 381.65 248.518125 \nL 381.65 0 \nL -0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 39.65 224.64 \nL 374.45 224.64 \nL 374.45 7.2 \nL 39.65 7.2 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path clip-path=\"url(#p60c308f684)\" d=\"M 54.868182 224.64 \nL 85.304545 224.64 \nL 85.304545 167.051128 \nL 54.868182 167.051128 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path clip-path=\"url(#p60c308f684)\" d=\"M 85.304545 224.64 \nL 115.740909 224.64 \nL 115.740909 224.64 \nL 85.304545 224.64 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path clip-path=\"url(#p60c308f684)\" d=\"M 115.740909 224.64 \nL 146.177273 224.64 \nL 146.177273 195.921942 \nL 115.740909 195.921942 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path clip-path=\"url(#p60c308f684)\" d=\"M 146.177273 224.64 \nL 176.613636 224.64 \nL 176.613636 224.64 \nL 146.177273 224.64 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_7\">\n    <path clip-path=\"url(#p60c308f684)\" d=\"M 176.613636 224.64 \nL 207.05 224.64 \nL 207.05 224.64 \nL 176.613636 224.64 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_8\">\n    <path clip-path=\"url(#p60c308f684)\" d=\"M 207.05 224.64 \nL 237.486364 224.64 \nL 237.486364 185.890989 \nL 207.05 185.890989 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_9\">\n    <path clip-path=\"url(#p60c308f684)\" d=\"M 237.486364 224.64 \nL 267.922727 224.64 \nL 267.922727 224.64 \nL 237.486364 224.64 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_10\">\n    <path clip-path=\"url(#p60c308f684)\" d=\"M 267.922727 224.64 \nL 298.359091 224.64 \nL 298.359091 149.433312 \nL 267.922727 149.433312 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_11\">\n    <path clip-path=\"url(#p60c308f684)\" d=\"M 298.359091 224.64 \nL 328.795455 224.64 \nL 328.795455 224.64 \nL 298.359091 224.64 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_12\">\n    <path clip-path=\"url(#p60c308f684)\" d=\"M 328.795455 224.64 \nL 359.231818 224.64 \nL 359.231818 17.554286 \nL 328.795455 17.554286 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"m1f2d841079\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"54.868182\" xlink:href=\"#m1f2d841079\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 1.0 -->\n      <defs>\n       <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n       <path d=\"M 10.6875 12.40625 \nL 21 12.40625 \nL 21 0 \nL 10.6875 0 \nz\n\" id=\"DejaVuSans-46\"/>\n       <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n      </defs>\n      <g transform=\"translate(46.916619 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"92.913636\" xlink:href=\"#m1f2d841079\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 1.5 -->\n      <defs>\n       <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n      </defs>\n      <g transform=\"translate(84.962074 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"130.959091\" xlink:href=\"#m1f2d841079\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 2.0 -->\n      <defs>\n       <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n      </defs>\n      <g transform=\"translate(123.007528 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"169.004545\" xlink:href=\"#m1f2d841079\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 2.5 -->\n      <g transform=\"translate(161.052983 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"207.05\" xlink:href=\"#m1f2d841079\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 3.0 -->\n      <defs>\n       <path d=\"M 40.578125 39.3125 \nQ 47.65625 37.796875 51.625 33 \nQ 55.609375 28.21875 55.609375 21.1875 \nQ 55.609375 10.40625 48.1875 4.484375 \nQ 40.765625 -1.421875 27.09375 -1.421875 \nQ 22.515625 -1.421875 17.65625 -0.515625 \nQ 12.796875 0.390625 7.625 2.203125 \nL 7.625 11.71875 \nQ 11.71875 9.328125 16.59375 8.109375 \nQ 21.484375 6.890625 26.8125 6.890625 \nQ 36.078125 6.890625 40.9375 10.546875 \nQ 45.796875 14.203125 45.796875 21.1875 \nQ 45.796875 27.640625 41.28125 31.265625 \nQ 36.765625 34.90625 28.71875 34.90625 \nL 20.21875 34.90625 \nL 20.21875 43.015625 \nL 29.109375 43.015625 \nQ 36.375 43.015625 40.234375 45.921875 \nQ 44.09375 48.828125 44.09375 54.296875 \nQ 44.09375 59.90625 40.109375 62.90625 \nQ 36.140625 65.921875 28.71875 65.921875 \nQ 24.65625 65.921875 20.015625 65.03125 \nQ 15.375 64.15625 9.8125 62.3125 \nL 9.8125 71.09375 \nQ 15.4375 72.65625 20.34375 73.4375 \nQ 25.25 74.21875 29.59375 74.21875 \nQ 40.828125 74.21875 47.359375 69.109375 \nQ 53.90625 64.015625 53.90625 55.328125 \nQ 53.90625 49.265625 50.4375 45.09375 \nQ 46.96875 40.921875 40.578125 39.3125 \nz\n\" id=\"DejaVuSans-51\"/>\n      </defs>\n      <g transform=\"translate(199.098438 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"245.095455\" xlink:href=\"#m1f2d841079\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 3.5 -->\n      <g transform=\"translate(237.143892 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_7\">\n     <g id=\"line2d_7\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"283.140909\" xlink:href=\"#m1f2d841079\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 4.0 -->\n      <defs>\n       <path d=\"M 37.796875 64.3125 \nL 12.890625 25.390625 \nL 37.796875 25.390625 \nz\nM 35.203125 72.90625 \nL 47.609375 72.90625 \nL 47.609375 25.390625 \nL 58.015625 25.390625 \nL 58.015625 17.1875 \nL 47.609375 17.1875 \nL 47.609375 0 \nL 37.796875 0 \nL 37.796875 17.1875 \nL 4.890625 17.1875 \nL 4.890625 26.703125 \nz\n\" id=\"DejaVuSans-52\"/>\n      </defs>\n      <g transform=\"translate(275.189347 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-52\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_8\">\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"321.186364\" xlink:href=\"#m1f2d841079\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 4.5 -->\n      <g transform=\"translate(313.234801 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-52\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_9\">\n     <g id=\"line2d_9\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"359.231818\" xlink:href=\"#m1f2d841079\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 5.0 -->\n      <g transform=\"translate(351.280256 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_10\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"m473648d5ef\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"39.65\" xlink:href=\"#m473648d5ef\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 0 -->\n      <g transform=\"translate(26.2875 228.439219)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_11\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"39.65\" xlink:href=\"#m473648d5ef\" y=\"199.180729\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 500 -->\n      <g transform=\"translate(13.5625 202.979947)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"39.65\" xlink:href=\"#m473648d5ef\" y=\"173.721457\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 1000 -->\n      <g transform=\"translate(7.2 177.520676)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_13\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"39.65\" xlink:href=\"#m473648d5ef\" y=\"148.262186\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 1500 -->\n      <g transform=\"translate(7.2 152.061404)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_14\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"39.65\" xlink:href=\"#m473648d5ef\" y=\"122.802914\"/>\n      </g>\n     </g>\n     <g id=\"text_14\">\n      <!-- 2000 -->\n      <g transform=\"translate(7.2 126.602133)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_15\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"39.65\" xlink:href=\"#m473648d5ef\" y=\"97.343643\"/>\n      </g>\n     </g>\n     <g id=\"text_15\">\n      <!-- 2500 -->\n      <g transform=\"translate(7.2 101.142861)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_7\">\n     <g id=\"line2d_16\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"39.65\" xlink:href=\"#m473648d5ef\" y=\"71.884371\"/>\n      </g>\n     </g>\n     <g id=\"text_16\">\n      <!-- 3000 -->\n      <g transform=\"translate(7.2 75.68359)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_8\">\n     <g id=\"line2d_17\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"39.65\" xlink:href=\"#m473648d5ef\" y=\"46.4251\"/>\n      </g>\n     </g>\n     <g id=\"text_17\">\n      <!-- 3500 -->\n      <g transform=\"translate(7.2 50.224318)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_9\">\n     <g id=\"line2d_18\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"39.65\" xlink:href=\"#m473648d5ef\" y=\"20.965828\"/>\n      </g>\n     </g>\n     <g id=\"text_18\">\n      <!-- 4000 -->\n      <g transform=\"translate(7.2 24.765047)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-52\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"patch_13\">\n    <path d=\"M 39.65 224.64 \nL 39.65 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_14\">\n    <path d=\"M 374.45 224.64 \nL 374.45 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_15\">\n    <path d=\"M 39.65 224.64 \nL 374.45 224.64 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_16\">\n    <path d=\"M 39.65 7.2 \nL 374.45 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p60c308f684\">\n   <rect height=\"217.44\" width=\"334.8\" x=\"39.65\" y=\"7.2\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "df.overall.hist(grid=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF - 100 dimension, 2-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndim = 100\n",
    "n_grams = 2\n",
    "\n",
    "# 1. TF-IDF\n",
    "tfidf100 = TfidfVectorizer(ngram_range=(1, n_grams),\n",
    "                                max_features=ndim)\n",
    "tfidf100_train_matrix = tfidf100.fit_transform(train_docs).toarray()\n",
    "tfidf100_val_matrix = tfidf100.transform(val_docs).toarray()\n",
    "tfidf100_test_matrix = tfidf100.transform(test_docs).toarray()\n",
    "\n",
    "rf_tfidf100_train = tfidf100.fit_transform(rf_train_docs).toarray()\n",
    "rf_tfidf100_test = tfidf100.transform(test_docs).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export arrays for modeling\n",
    "np.save('embeddings_arrays/tfidf100_train.npy', tfidf100_train_matrix)\n",
    "np.save('embeddings_arrays/tfidf100_val.npy', tfidf100_val_matrix)\n",
    "np.save('embeddings_arrays/tfidf100_test.npy', tfidf100_test_matrix)\n",
    "np.save('embeddings_arrays/tfidf100_rf_train.npy', rf_tfidf100_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#{k: v for k, v in sorted(tfidf_100.vocabulary_.items(), key=lambda item: item[1], reverse=True)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF 200 dimension, 1-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf200 = TfidfVectorizer(max_features=200) # default n-gram is 1\n",
    "tfidf200_train_matrix = tfidf200.fit_transform(train_docs).toarray()\n",
    "tfidf200_val_matrix = tfidf200.transform(val_docs).toarray()\n",
    "tfidf200_test_matrix = tfidf200.transform(test_docs).toarray()\n",
    "rf_tfidf200_train = tfidf200.fit_transform(rf_train_docs).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export matrices\n",
    "np.save('embeddings_arrays/tfidf200_train.npy', tfidf200_train_matrix)\n",
    "np.save('embeddings_arrays/tfidf200_val.npy', tfidf200_val_matrix)\n",
    "np.save('embeddings_arrays/tfidf200_test.npy', tfidf200_test_matrix)\n",
    "np.save('embeddings_arrays/tfidf200_rf_train.npy', rf_tfidf200_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GloVe - 100 dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tutorial: https://blog.keras.io/using-pre-trained-word-embeddings-in-a-keras-model.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required packages\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Found 400000 word vectors.\n"
    }
   ],
   "source": [
    "glove100_path = 'glove.6B/glove.6B.100d.txt'\n",
    "ndim = 100\n",
    "glove100_embeddings_index = {}\n",
    "with open(glove100_path) as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        ps=PorterStemmer()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        glove100_embeddings_index[word] = coefs\n",
    "\n",
    "print('Found %s word vectors.' % len(glove100_embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "word_count = lambda sentence: len(word_tokenize(sentence))\n",
    "length_long_sentence = len(max(train_docs, key=word_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words = 5000)\n",
    "tokenizer.fit_on_texts(train_docs)\n",
    "sequences = tokenizer.texts_to_sequences(train_docs)\n",
    "glove100_train = pad_sequences(sequences, length_long_sentence)\n",
    "word_index = tokenizer.word_index\n",
    "len(word_index)\n",
    "\n",
    "glove100_test = tokenizer.texts_to_sequences(test_docs)\n",
    "glove100_test = np.asarray(pad_sequences(glove100_test, length_long_sentence))\n",
    "glove100_val = tokenizer.texts_to_sequences(val_docs)\n",
    "glove100_val = np.asarray(pad_sequences(glove100_val, length_long_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required or to_categorical creates 6 labels\n",
    "#labels = np.asarray(df.overall.apply(lambda x: x-1))\n",
    "train_labels = np.asarray(train.overall.apply(lambda x: x-1))\n",
    "val_labels = np.asarray(val.overall.apply(lambda x: x-1))\n",
    "test_labels = np.asarray(test.overall.apply(lambda x: x-1))\n",
    "rf_train_labels = np.asarray(rf_train.overall.apply(lambda x: x-1))\n",
    "\n",
    "\n",
    "train_labels = to_categorical(train_labels, num_classes=5) # number of classes, 1-5 ratings\n",
    "glove_val_labels = to_categorical(val_labels, num_classes=5)\n",
    "glove_test_labels = to_categorical(test_labels, num_classes=5)\n",
    "rf_train_labels = to_categorical(rf_train_labels, num_classes = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "((4801, 1689), (1601, 1689), (4801, 5), (1601, 5), (1598, 5))"
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "source": [
    "glove100_train.shape, glove100_val.shape, train_labels.shape, glove_val_labels.shape, glove_test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save labels\n",
    "np.save('embeddings_arrays/train_labels.npy', train_labels)\n",
    "np.save('embeddings_arrays/val_labels.npy', val_labels)\n",
    "np.save('embeddings_arrays/test_labels.npy', test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove100_embedding_matrix = np.zeros((len(word_index) + 1, ndim))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = glove100_embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        glove100_embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding\n",
    "\n",
    "glove100_embedding_layer = Embedding(len(word_index) + 1, # input len(embedding array)\n",
    "                            100,\n",
    "                            weights=[glove100_embedding_matrix],\n",
    "                            input_length=length_long_sentence,\n",
    "                            trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence100_input = Input(shape=(100,), dtype='int32')\n",
    "glove100embedded_sequences = glove100_embedding_layer(sequence100_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export weights\n",
    "np.save('embeddings_arrays/glove100_weights.npy', glove100_embedding_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Glove 200 dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndim = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Found 400000 word vectors.\n"
    }
   ],
   "source": [
    "glove200_path = 'glove.6B/glove.6B.200d.txt'\n",
    "glove200_embeddings_index = {}\n",
    "with open(glove200_path) as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        glove200_embeddings_index[word] = coefs\n",
    "\n",
    "print('Found %s word vectors.' % len(glove200_embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = list()\n",
    "tokenizer = Tokenizer(num_words = 5000)\n",
    "tokenizer.fit_on_texts(train_docs)\n",
    "sequences = tokenizer.texts_to_sequences(train_docs)\n",
    "glove200_train = pad_sequences(sequences, length_long_sentence)\n",
    "word_index = tokenizer.word_index\n",
    "len(word_index)\n",
    "\n",
    "glove200_test = tokenizer.texts_to_sequences(test_docs)\n",
    "glove200_test = pad_sequences(glove200_test, length_long_sentence)\n",
    "glove200_val = tokenizer.texts_to_sequences(val_docs)\n",
    "glove200_val = pad_sequences(glove200_val, length_long_sentence)\n",
    "# Reuse glove train/val/test labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove200_embedding_matrix = np.zeros((len(word_index) + 1, ndim))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = glove200_embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        glove200_embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove200_embedding_layer = Embedding(len(word_index) + 1,\n",
    "                            200,\n",
    "                            weights=[glove200_embedding_matrix],\n",
    "                            input_length=length_long_sentence,\n",
    "                            trainable=False)\n",
    "\n",
    "sequence200_input = Input(shape=(200,), dtype='int32')\n",
    "glove200_embedded_sequences = glove200_embedding_layer(sequence200_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export glove200 weights\n",
    "np.save('embeddings_arrays/glove200_weights.npy', glove200_embedding_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "glove_100_embedding_layer and glove_200_embedding_layer are now layers that go in as training layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model, train mse, train time, val loss, test mse\n",
    "regression_results = list()\n",
    "\n",
    "# model, train time, train f1, val f1, test loss, test f1\n",
    "classifier_results = list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_train_labels = np.asarray(rf_train.overall)\n",
    "rf_test_labels = np.asarray(test.overall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF 100 terms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try both classifier and regressor to compare F1 and RMSE scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dict()\n",
    "rfc = RandomForestClassifier(random_state=seed, n_estimators=100)\n",
    "rfr = RandomForestRegressor(random_state=seed, n_estimators=100)\n",
    "\n",
    "start = time.time()\n",
    "rfc.fit(rf_tfidf100_train, rf_train_labels)\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(1.756, 0.251)"
     },
     "metadata": {},
     "execution_count": 51
    }
   ],
   "source": [
    "cv_scores = cross_val_score(rfc, rf_tfidf100_train, \n",
    "                    rf_train_labels, cv=5, scoring='f1_macro', \n",
    "                    n_jobs=-1)\n",
    "\n",
    "train_time = parse_time(start, end)\n",
    "train_time, round(np.mean(cv_scores),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_train_preds = rfc.predict(rf_tfidf100_train)\n",
    "rfc_preds = rfc.predict(tfidf100_test_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'model': 'RF TF-IDF 100 terms',\n 'train_f1': 0.986,\n 'train_time': 1.756,\n 'val_f1': 0.251,\n 'test_f1': 0.03}"
     },
     "metadata": {},
     "execution_count": 53
    }
   ],
   "source": [
    "data['model'] = 'RF TF-IDF 100 terms'\n",
    "data['train_f1'] = round(f1_score(rfc_train_preds, rf_train_labels, average='macro'), 3)\n",
    "data['train_time'] = parse_time(start, end)\n",
    "data['val_f1'] = round(np.mean(cv_scores), 3)\n",
    "data['test_f1'] = round(f1_score(rfc_preds, test_labels, average='macro'), 3)\n",
    "classifier_results.append(data)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dict()\n",
    "start = time.time()\n",
    "rfr.fit(rf_tfidf100_train, rf_train_labels)\n",
    "end = time.time()\n",
    "\n",
    "train_time = parse_time(start, end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_scores = cross_val_score(rfr, rf_tfidf100_train, rf_train_labels,\n",
    "                    n_jobs=-1, scoring='neg_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "2.289336309336181"
     },
     "metadata": {},
     "execution_count": 56
    }
   ],
   "source": [
    "rfr_train_preds = rfr.predict(rf_tfidf100_train)\n",
    "rfr_preds = rfr.predict(tfidf100_test_matrix)\n",
    "mean_squared_error(rfr_train_preds, rf_train_labels)\n",
    "mean_squared_error(rfr_preds, rf_test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'model': 'RF TF-IDF 100 dim',\n 'train_mse': 0.291,\n 'train_time': 12.075,\n 'val_mse': 1.793,\n 'test_mse': 2.289}"
     },
     "metadata": {},
     "execution_count": 57
    }
   ],
   "source": [
    "data['model'] = 'RF TF-IDF 100 dim'\n",
    "data['train_mse'] = round(mean_squared_error(rfr_train_preds, rf_train_labels), 3)\n",
    "data['train_time'] = train_time\n",
    "data['val_mse'] = round(np.abs(np.mean(cv_scores)), 3)\n",
    "data['test_mse'] = round(mean_squared_error(rfr_preds, rf_test_labels), 3)\n",
    "regression_results.append(data)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF 200 terms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dict()\n",
    "start = time.time()\n",
    "rfc.fit(rf_tfidf200_train, rf_train_labels)\n",
    "end = time.time()\n",
    "\n",
    "cv_scores = cross_val_score(rfc, rf_tfidf200_train, \n",
    "                    rf_train_labels, cv=3, scoring='f1_macro', \n",
    "                    n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.024386237172496713"
     },
     "metadata": {},
     "execution_count": 59
    }
   ],
   "source": [
    "rfc_train_preds = rfc.predict(rf_tfidf200_train)\n",
    "rfc_preds = rfc.predict(tfidf200_test_matrix)\n",
    "\n",
    "f1_score(rfc_train_preds, rf_train_labels, average='macro')\n",
    "f1_score(rfc_preds, test_labels, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'model': 'RF TF-IDF 200 terms',\n 'train_f1': 0.998,\n 'train_time': 2.066,\n 'val_f1': 0.252,\n 'test_f1': 0.024}"
     },
     "metadata": {},
     "execution_count": 60
    }
   ],
   "source": [
    "data['model'] = 'RF TF-IDF 200 terms'\n",
    "data['train_f1'] = round(f1_score(rfc_train_preds, rf_train_labels, average='macro'), 3)\n",
    "data['train_time'] = parse_time(start, end)\n",
    "data['val_f1'] = round(np.mean(cv_scores), 3)\n",
    "data['test_f1'] = round(f1_score(rfc_preds, test_labels, average='macro'), 3)\n",
    "classifier_results.append(data)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dict()\n",
    "start = time.time()\n",
    "rfr.fit(rf_tfidf200_train, rf_train_labels)\n",
    "end = time.time()\n",
    "\n",
    "cv_scores = cross_val_score(rfr, rf_tfidf200_train, rf_train_labels,\n",
    "                    n_jobs=-1, scoring='neg_mean_absolute_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "2.7751832473113383"
     },
     "metadata": {},
     "execution_count": 62
    }
   ],
   "source": [
    "rfr_train_preds = rfr.predict(rf_tfidf200_train)\n",
    "rfr_preds = rfr.predict(tfidf200_test_matrix)\n",
    "\n",
    "mean_squared_error(rfr_train_preds, rf_train_labels)\n",
    "mean_squared_error(rfr_preds, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'model': 'RF TF-IDF 200 dim',\n 'train_mse': 0.232,\n 'train_time': 12.075,\n 'val_mse': 1.012,\n 'test_mse': 2.775}"
     },
     "metadata": {},
     "execution_count": 63
    }
   ],
   "source": [
    "data['model'] = 'RF TF-IDF 200 dim'\n",
    "data['train_mse'] = round(mean_squared_error(rfr_train_preds, rf_train_labels), 3)\n",
    "data['train_time'] = train_time\n",
    "data['val_mse'] = round(np.abs(np.mean(cv_scores)), 3)\n",
    "data['test_mse'] = round(mean_squared_error(rfr_preds, test_labels), 3)\n",
    "regression_results.append(data)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dense Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GloVe 100 dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding (Embedding)        multiple                  1714500   \n_________________________________________________________________\nflatten (Flatten)            (None, 168900)            0         \n_________________________________________________________________\ndense (Dense)                (None, 128)               21619328  \n_________________________________________________________________\ndense_1 (Dense)              (None, 5)                 645       \n=================================================================\nTotal params: 23,334,473\nTrainable params: 21,619,973\nNon-trainable params: 1,714,500\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "sequence100_input = Input(shape=(length_long_sentence,), dtype='int32')\n",
    "glove100_embedded_sequences = glove100_embedding_layer(sequence100_input)\n",
    "\n",
    "model = Sequential([\n",
    "    sequence100_input,\n",
    "    glove100_embedding_layer,\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(5, activation = 'softmax')\n",
    "])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "opt = 'rmsprop'\n",
    "\n",
    "model.compile(\n",
    "    optimizer=opt,\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/10\n151/151 [==============================] - 21s 138ms/step - loss: 1.3513 - accuracy: 0.5020 - val_loss: 1.2919 - val_accuracy: 0.5334\nEpoch 2/10\n151/151 [==============================] - 21s 141ms/step - loss: 1.0110 - accuracy: 0.5982 - val_loss: 1.8154 - val_accuracy: 0.3841\nEpoch 3/10\n151/151 [==============================] - 21s 139ms/step - loss: 0.6931 - accuracy: 0.7342 - val_loss: 1.3970 - val_accuracy: 0.5153\nEpoch 4/10\n151/151 [==============================] - 21s 142ms/step - loss: 0.4375 - accuracy: 0.8494 - val_loss: 1.7655 - val_accuracy: 0.4029\nEpoch 5/10\n151/151 [==============================] - 22s 143ms/step - loss: 0.2484 - accuracy: 0.9271 - val_loss: 2.1063 - val_accuracy: 0.3592\nEpoch 6/10\n151/151 [==============================] - 22s 145ms/step - loss: 0.1445 - accuracy: 0.9650 - val_loss: 2.1614 - val_accuracy: 0.4697\nEpoch 7/10\n151/151 [==============================] - 22s 145ms/step - loss: 0.0769 - accuracy: 0.9842 - val_loss: 2.8238 - val_accuracy: 0.3960\nEpoch 8/10\n151/151 [==============================] - 22s 143ms/step - loss: 0.0416 - accuracy: 0.9950 - val_loss: 2.6974 - val_accuracy: 0.4347\nEpoch 9/10\n151/151 [==============================] - 22s 143ms/step - loss: 0.0241 - accuracy: 0.9956 - val_loss: 3.0918 - val_accuracy: 0.4722\nEpoch 10/10\n151/151 [==============================] - 22s 146ms/step - loss: 0.0129 - accuracy: 0.9981 - val_loss: 3.3650 - val_accuracy: 0.4310\n"
    }
   ],
   "source": [
    "data = dict()\n",
    "start = time.time()\n",
    "model.fit(glove100_train, train_labels,\n",
    "            validation_data=(glove100_val, glove_val_labels),\n",
    "            epochs = 10,\n",
    "            batch_size=32)\n",
    "\n",
    "end = time.time()\n",
    "train_time = parse_time(start, end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "50/50 [==============================] - 1s 13ms/step - loss: 3.1508 - accuracy: 0.4675\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(3.150829792022705, 0.4674593210220337)"
     },
     "metadata": {},
     "execution_count": 66
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(np.asarray(glove100_test), glove_test_labels)\n",
    "test_loss, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([0., 0., 0., 0., 1.], dtype=float32)"
     },
     "metadata": {},
     "execution_count": 67
    }
   ],
   "source": [
    "train_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate train F1 score\n",
    "train_preds = model.predict(glove100_train)\n",
    "train_f1 = f1_score(np.argmax(train_preds, axis=1), \n",
    "                    np.argmax(train_labels, axis=1), \n",
    "                    average='macro')\n",
    "# Generate test F1 score                    \n",
    "preds = model.predict(glove100_test)\n",
    "dnn_preds = model.predict(glove100_test)\n",
    "test_f1 = f1_score(np.argmax(preds, axis=1), test_labels, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'model': 'DNN (1 layer) - GloVe 100 dim',\n 'train_f1': 1.0,\n 'train_time': 217.012,\n 'test_f1': 0.312}"
     },
     "metadata": {},
     "execution_count": 69
    }
   ],
   "source": [
    "data['model'] = 'DNN (1 layer) - GloVe 100 dim'\n",
    "data['train_f1'] = round(train_f1, 3)\n",
    "data['train_time'] = train_time\n",
    "data['test_f1'] = round(test_f1, 3)\n",
    "classifier_results.append(data)\n",
    "data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-layer GloVe 100 dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"sequential_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding (Embedding)        multiple                  1714500   \n_________________________________________________________________\nflatten_1 (Flatten)          (None, 168900)            0         \n_________________________________________________________________\ndense_2 (Dense)              (None, 128)               21619328  \n_________________________________________________________________\ndense_3 (Dense)              (None, 256)               33024     \n_________________________________________________________________\ndense_4 (Dense)              (None, 5)                 1285      \n=================================================================\nTotal params: 23,368,137\nTrainable params: 21,653,637\nNon-trainable params: 1,714,500\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "sequence100_input = Input(shape=(length_long_sentence,), dtype='int32')\n",
    "glove100_embedded_sequences = glove100_embedding_layer(sequence100_input)\n",
    "\n",
    "model = Sequential([\n",
    "    sequence100_input,\n",
    "    glove100_embedding_layer,\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(5, kernel_initializer='normal')\n",
    "])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "opt = 'rmsprop'\n",
    "\n",
    "model.compile(\n",
    "    optimizer=opt,\n",
    "    loss='mean_squared_error'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "model.fit(glove100_train, train_labels,\n",
    "            validation_data=(glove100_val, glove_val_labels),\n",
    "            epochs = 15,\n",
    "            batch_size=32)\n",
    "end = time.time()\n",
    "train_time = parse_time(start, end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = model.predict(glove100_train)\n",
    "test_preds = model.predict(glove100_test)\n",
    "\n",
    "train_mse = mean_squared_error(np.argmax(train_preds, axis = 1), \n",
    "                                np.argmax(train_labels, axis=1))\n",
    "test_mse = mean_squared_error(np.argmax(test_preds, axis = 1), test_labels)\n",
    "\n",
    "train_mse, test_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dict()\n",
    "data['model'] = 'DNN (2 layers) - GloVe 100 dim'\n",
    "data['train_f1'] = round(train_f1, 3)\n",
    "data['train_time'] = train_time\n",
    "data['test_f1'] = round(test_f1, 3)\n",
    "classifier_results.append(data)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Glove 200 dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"sequential_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding_1 (Embedding)      multiple                  2568600   \n_________________________________________________________________\nflatten_1 (Flatten)          (None, 341400)            0         \n_________________________________________________________________\ndense_2 (Dense)              (None, 128)               43699328  \n_________________________________________________________________\ndense_3 (Dense)              (None, 5)                 645       \n=================================================================\nTotal params: 46,268,573\nTrainable params: 43,699,973\nNon-trainable params: 2,568,600\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "sequence200_input = Input(shape=(length_long_sentence,), dtype='int32')\n",
    "glove200_embedded_sequences = glove200_embedding_layer(sequence200_input)\n",
    "\n",
    "model = Sequential([\n",
    "    sequence200_input,\n",
    "    glove200_embedding_layer,\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(5, activation = 'softmax')\n",
    "])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "opt = 'rmsprop'\n",
    "\n",
    "model.compile(\n",
    "    optimizer=opt,\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/10\n94/94 [==============================] - 25s 267ms/step - loss: 1.2250 - accuracy: 0.6075 - val_loss: 1.0526 - val_accuracy: 0.6384\nEpoch 2/10\n94/94 [==============================] - 25s 268ms/step - loss: 0.6465 - accuracy: 0.7544 - val_loss: 1.3034 - val_accuracy: 0.6124\nEpoch 3/10\n94/94 [==============================] - 25s 269ms/step - loss: 0.3400 - accuracy: 0.8857 - val_loss: 1.3825 - val_accuracy: 0.6084\nEpoch 4/10\n94/94 [==============================] - 25s 270ms/step - loss: 0.1731 - accuracy: 0.9470 - val_loss: 1.6843 - val_accuracy: 0.5984\nEpoch 5/10\n94/94 [==============================] - 26s 273ms/step - loss: 0.0785 - accuracy: 0.9790 - val_loss: 1.9489 - val_accuracy: 0.5994\nEpoch 6/10\n94/94 [==============================] - 26s 276ms/step - loss: 0.0301 - accuracy: 0.9963 - val_loss: 2.3928 - val_accuracy: 0.6024\nEpoch 7/10\n94/94 [==============================] - 26s 279ms/step - loss: 0.0167 - accuracy: 0.9973 - val_loss: 2.6290 - val_accuracy: 0.6014\nEpoch 8/10\n94/94 [==============================] - 26s 274ms/step - loss: 0.0111 - accuracy: 0.9987 - val_loss: 2.9721 - val_accuracy: 0.6004\nEpoch 9/10\n94/94 [==============================] - 25s 270ms/step - loss: 0.0075 - accuracy: 0.9990 - val_loss: 3.2986 - val_accuracy: 0.6064\nEpoch 10/10\n94/94 [==============================] - 26s 277ms/step - loss: 0.0049 - accuracy: 0.9997 - val_loss: 3.4253 - val_accuracy: 0.6064\n"
    }
   ],
   "source": [
    "start = time.time()\n",
    "model.fit(glove200_train, train_labels,\n",
    "            validation_data=(glove200_val, glove_val_labels),\n",
    "            epochs = 10,\n",
    "            batch_size=32)\n",
    "\n",
    "end = time.time()\n",
    "train_time = parse_time(start, end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "32/32 [==============================] - 1s 23ms/step - loss: 3.2760 - accuracy: 0.6222\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[3.27604079246521, 0.6222444772720337]"
     },
     "metadata": {},
     "execution_count": 72
    }
   ],
   "source": [
    "model.evaluate(np.asarray(glove200_test), glove_test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate train F1 score\n",
    "train_preds = model.predict(glove200_train)\n",
    "train_f1 = f1_score(np.argmax(train_preds, axis=1), \n",
    "                    np.argmax(train_labels, axis=1), \n",
    "                    average='macro')\n",
    "# Generate test F1 score                    \n",
    "preds = model.predict(glove200_test)\n",
    "test_f1 = f1_score(np.argmax(preds, axis=1), test_labels, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(0.9997376238378614, 0.2800811415695021)"
     },
     "metadata": {},
     "execution_count": 74
    }
   ],
   "source": [
    "train_f1, test_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'model': 'DNN (1 layer) - GloVe 200 dim',\n 'train_f1': 1.0,\n 'train_time': 259.123,\n 'test_f1': 0.28}"
     },
     "metadata": {},
     "execution_count": 75
    }
   ],
   "source": [
    "data = dict()\n",
    "data['model'] = 'DNN (1 layer) - GloVe 200 dim'\n",
    "data['train_f1'] = round(train_f1, 3)\n",
    "data['train_time'] = train_time\n",
    "data['test_f1'] = round(test_f1, 3)\n",
    "classifier_results.append(data)\n",
    "data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF 100 dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"sequential_2\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_4 (Dense)              (None, 32)                3232      \n_________________________________________________________________\ndense_5 (Dense)              (None, 128)               4224      \n_________________________________________________________________\ndense_6 (Dense)              (None, 5)                 645       \n=================================================================\nTotal params: 8,101\nTrainable params: 8,101\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Dense(32, input_shape=(100,)),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(5, activation = 'softmax')\n",
    "])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "opt = 'rmsprop'\n",
    "\n",
    "model.compile(\n",
    "    optimizer=opt,\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/15\n94/94 [==============================] - 0s 956us/step - loss: 1.1763 - accuracy: 0.6205\nEpoch 2/15\n94/94 [==============================] - 0s 952us/step - loss: 1.0298 - accuracy: 0.6335\nEpoch 3/15\n94/94 [==============================] - 0s 909us/step - loss: 0.9813 - accuracy: 0.6471\nEpoch 4/15\n94/94 [==============================] - 0s 783us/step - loss: 0.9524 - accuracy: 0.6544\nEpoch 5/15\n94/94 [==============================] - 0s 831us/step - loss: 0.9356 - accuracy: 0.6574\nEpoch 6/15\n94/94 [==============================] - 0s 805us/step - loss: 0.9236 - accuracy: 0.6581\nEpoch 7/15\n94/94 [==============================] - 0s 802us/step - loss: 0.9153 - accuracy: 0.6584\nEpoch 8/15\n94/94 [==============================] - 0s 805us/step - loss: 0.9101 - accuracy: 0.6624\nEpoch 9/15\n94/94 [==============================] - 0s 918us/step - loss: 0.9036 - accuracy: 0.6614\nEpoch 10/15\n94/94 [==============================] - 0s 973us/step - loss: 0.8993 - accuracy: 0.6634\nEpoch 11/15\n94/94 [==============================] - 0s 939us/step - loss: 0.8925 - accuracy: 0.6684\nEpoch 12/15\n94/94 [==============================] - 0s 825us/step - loss: 0.8895 - accuracy: 0.6684\nEpoch 13/15\n94/94 [==============================] - 0s 861us/step - loss: 0.8857 - accuracy: 0.6658\nEpoch 14/15\n94/94 [==============================] - 0s 936us/step - loss: 0.8822 - accuracy: 0.6684\nEpoch 15/15\n94/94 [==============================] - 0s 993us/step - loss: 0.8766 - accuracy: 0.6708\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x7fb386fa19d0>"
     },
     "metadata": {},
     "execution_count": 77
    }
   ],
   "source": [
    "model.fit(tfidf100_train_matrix, train_labels,\n",
    "            epochs=15,\n",
    "            batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "32/32 [==============================] - 0s 889us/step - loss: 0.9725 - accuracy: 0.6593\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[0.9724795818328857, 0.6593186259269714]"
     },
     "metadata": {},
     "execution_count": 78
    }
   ],
   "source": [
    "preds = model.predict(tfidf100_test_matrix)\n",
    "model.evaluate(tfidf100_test_matrix, glove_test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.2850232835369447"
     },
     "metadata": {},
     "execution_count": 79
    }
   ],
   "source": [
    "f1_score(np.argmax(preds, axis=1), test_labels, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF 200 dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"sequential_3\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_7 (Dense)              (None, 32)                6432      \n_________________________________________________________________\ndense_8 (Dense)              (None, 128)               4224      \n_________________________________________________________________\ndense_9 (Dense)              (None, 5)                 645       \n=================================================================\nTotal params: 11,301\nTrainable params: 11,301\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Dense(32, input_shape=(200,)),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(5, activation = 'softmax')\n",
    "])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "opt = 'rmsprop'\n",
    "\n",
    "model.compile(\n",
    "    optimizer=opt,\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/15\n94/94 [==============================] - 0s 2ms/step - loss: 1.1502 - accuracy: 0.6215\nEpoch 2/15\n94/94 [==============================] - 0s 1ms/step - loss: 0.9981 - accuracy: 0.6371\nEpoch 3/15\n94/94 [==============================] - 0s 1ms/step - loss: 0.9465 - accuracy: 0.6581\nEpoch 4/15\n94/94 [==============================] - 0s 1ms/step - loss: 0.9174 - accuracy: 0.6654\nEpoch 5/15\n94/94 [==============================] - 0s 1ms/step - loss: 0.8951 - accuracy: 0.6748\nEpoch 6/15\n94/94 [==============================] - 0s 1ms/step - loss: 0.8767 - accuracy: 0.6801\nEpoch 7/15\n94/94 [==============================] - 0s 999us/step - loss: 0.8585 - accuracy: 0.6831\nEpoch 8/15\n94/94 [==============================] - 0s 1ms/step - loss: 0.8456 - accuracy: 0.6918\nEpoch 9/15\n94/94 [==============================] - 0s 1ms/step - loss: 0.8339 - accuracy: 0.6911\nEpoch 10/15\n94/94 [==============================] - 0s 955us/step - loss: 0.8234 - accuracy: 0.6934\nEpoch 11/15\n94/94 [==============================] - 0s 1ms/step - loss: 0.8148 - accuracy: 0.6971\nEpoch 12/15\n94/94 [==============================] - 0s 951us/step - loss: 0.8076 - accuracy: 0.6988\nEpoch 13/15\n94/94 [==============================] - 0s 992us/step - loss: 0.8000 - accuracy: 0.7031\nEpoch 14/15\n94/94 [==============================] - 0s 990us/step - loss: 0.7932 - accuracy: 0.7041\nEpoch 15/15\n94/94 [==============================] - 0s 952us/step - loss: 0.7881 - accuracy: 0.7038\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x7fb386e1f3a0>"
     },
     "metadata": {},
     "execution_count": 81
    }
   ],
   "source": [
    "model.fit(tfidf200_train_matrix, train_labels,\n",
    "            epochs=15,\n",
    "            batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "32/32 [==============================] - 0s 768us/step - loss: 0.9707 - accuracy: 0.6503\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[0.9706652164459229, 0.6503006219863892]"
     },
     "metadata": {},
     "execution_count": 82
    }
   ],
   "source": [
    "preds = model.predict(tfidf200_test_matrix)\n",
    "model.evaluate(tfidf200_test_matrix, glove_test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.29811778383937754"
     },
     "metadata": {},
     "execution_count": 83
    }
   ],
   "source": [
    "f1_score(np.argmax(preds, axis=1), test_labels, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GloVe 100 dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"sequential_4\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding (Embedding)        multiple                  1284300   \n_________________________________________________________________\nflatten_2 (Flatten)          (None, 170700)            0         \n_________________________________________________________________\ndense_10 (Dense)             (None, 128)               21849728  \n_________________________________________________________________\ndense_11 (Dense)             (None, 5)                 645       \n=================================================================\nTotal params: 23,134,673\nTrainable params: 21,850,373\nNon-trainable params: 1,284,300\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "sequence100_input = Input(shape=(length_long_sentence,), dtype='int32')\n",
    "glove100_embedded_sequences = glove100_embedding_layer(sequence100_input)\n",
    "\n",
    "model = Sequential([\n",
    "    sequence100_input,\n",
    "    glove100_embedding_layer,\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(5, kernel_initializer='normal')\n",
    "])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "opt = 'rmsprop'\n",
    "\n",
    "model.compile(\n",
    "    optimizer=opt,\n",
    "    loss='mean_squared_error'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/10\n94/94 [==============================] - 14s 144ms/step - loss: 0.1616 - val_loss: 0.1080\nEpoch 2/10\n94/94 [==============================] - 13s 140ms/step - loss: 0.1054 - val_loss: 0.1105\nEpoch 3/10\n94/94 [==============================] - 13s 139ms/step - loss: 0.0746 - val_loss: 0.1160\nEpoch 4/10\n94/94 [==============================] - 13s 143ms/step - loss: 0.0557 - val_loss: 0.1195\nEpoch 5/10\n94/94 [==============================] - 13s 139ms/step - loss: 0.0419 - val_loss: 0.1182\nEpoch 6/10\n94/94 [==============================] - 14s 144ms/step - loss: 0.0332 - val_loss: 0.1258\nEpoch 7/10\n94/94 [==============================] - 13s 142ms/step - loss: 0.0269 - val_loss: 0.1224\nEpoch 8/10\n94/94 [==============================] - 13s 143ms/step - loss: 0.0228 - val_loss: 0.1210\nEpoch 9/10\n94/94 [==============================] - 13s 140ms/step - loss: 0.0202 - val_loss: 0.1239\nEpoch 10/10\n94/94 [==============================] - 13s 143ms/step - loss: 0.0180 - val_loss: 0.1216\n"
    }
   ],
   "source": [
    "start = time.time()\n",
    "model.fit(glove100_train, train_labels,\n",
    "            validation_data=(glove100_val, glove_val_labels),\n",
    "            epochs = 10,\n",
    "            batch_size=32)\n",
    "end = time.time()\n",
    "train_time = parse_time(start, end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "32/32 [==============================] - 0s 12ms/step - loss: 0.1203\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.12026270478963852"
     },
     "metadata": {},
     "execution_count": 86
    }
   ],
   "source": [
    "model.evaluate(np.asarray(glove100_test), glove_test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(0.09730089970009996, 1.9258517034068137)"
     },
     "metadata": {},
     "execution_count": 87
    }
   ],
   "source": [
    "train_preds = model.predict(glove100_train)\n",
    "test_preds = model.predict(glove100_test)\n",
    "\n",
    "train_mse = mean_squared_error(np.argmax(train_preds, axis = 1), \n",
    "                                np.argmax(train_labels, axis=1))\n",
    "test_mse = mean_squared_error(np.argmax(test_preds, axis = 1), test_labels)\n",
    "\n",
    "train_mse, test_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'model': 'DNN (1 layer) - GloVe 100 dim',\n 'train_mse': 0.097,\n 'train_time': 134.798,\n 'test_mse': 1.926}"
     },
     "metadata": {},
     "execution_count": 88
    }
   ],
   "source": [
    "data = dict()\n",
    "data['model'] = 'DNN (1 layer) - GloVe 100 dim'\n",
    "data['train_mse'] = round(train_mse, 3)\n",
    "data['train_time'] = train_time\n",
    "data['test_mse'] = round(test_mse, 3)\n",
    "\n",
    "regression_results.append(data)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GloVe 200 dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"sequential_5\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding_1 (Embedding)      multiple                  2568600   \n_________________________________________________________________\nflatten_3 (Flatten)          (None, 341400)            0         \n_________________________________________________________________\ndense_12 (Dense)             (None, 128)               43699328  \n_________________________________________________________________\ndense_13 (Dense)             (None, 5)                 645       \n=================================================================\nTotal params: 46,268,573\nTrainable params: 43,699,973\nNon-trainable params: 2,568,600\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "sequence200_input = Input(shape=(length_long_sentence,), dtype='int32')\n",
    "glove200_embedded_sequences = glove200_embedding_layer(sequence200_input)\n",
    "\n",
    "model = Sequential([\n",
    "    sequence200_input,\n",
    "    glove200_embedding_layer,\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(5, kernel_initializer='normal')\n",
    "])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "opt = 'rmsprop'\n",
    "\n",
    "model.compile(\n",
    "    optimizer=opt,\n",
    "    loss='mse',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/10\n94/94 [==============================] - 25s 262ms/step - loss: 0.2060 - val_loss: 0.1078\nEpoch 2/10\n94/94 [==============================] - 25s 269ms/step - loss: 0.1338 - val_loss: 0.1093\nEpoch 3/10\n94/94 [==============================] - 25s 269ms/step - loss: 0.0659 - val_loss: 0.1187\nEpoch 4/10\n94/94 [==============================] - 25s 263ms/step - loss: 0.0418 - val_loss: 0.1216\nEpoch 5/10\n94/94 [==============================] - 25s 263ms/step - loss: 0.0300 - val_loss: 0.1172\nEpoch 6/10\n94/94 [==============================] - 25s 269ms/step - loss: 0.0237 - val_loss: 0.1201\nEpoch 7/10\n94/94 [==============================] - 25s 265ms/step - loss: 0.0206 - val_loss: 0.1197\nEpoch 8/10\n94/94 [==============================] - 25s 264ms/step - loss: 0.0178 - val_loss: 0.1201\nEpoch 9/10\n94/94 [==============================] - 25s 263ms/step - loss: 0.0162 - val_loss: 0.1205\nEpoch 10/10\n94/94 [==============================] - 25s 270ms/step - loss: 0.0145 - val_loss: 0.1203\n"
    }
   ],
   "source": [
    "start = time.time()\n",
    "model.fit(glove200_train, train_labels,\n",
    "            validation_data=(glove200_val, glove_val_labels),\n",
    "            epochs = 10,\n",
    "            batch_size=32)\n",
    "\n",
    "end = time.time()\n",
    "train_time = parse_time(start, end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(0.062312562479173605, 1.8757515030060121)"
     },
     "metadata": {},
     "execution_count": 91
    }
   ],
   "source": [
    "train_preds = model.predict(glove200_train)\n",
    "test_preds = model.predict(glove200_test)\n",
    "\n",
    "train_mse = mean_squared_error(np.argmax(train_preds, axis = 1), \n",
    "                                np.argmax(train_labels, axis=1))\n",
    "test_mse = mean_squared_error(np.argmax(test_preds, axis = 1), test_labels)\n",
    "\n",
    "train_mse, test_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'model': 'DNN (1 layer) - GloVe 200 dim',\n 'train_mse': 0.062,\n 'train_time': 252.627,\n 'test_mse': 1.876}"
     },
     "metadata": {},
     "execution_count": 92
    }
   ],
   "source": [
    "data = dict()\n",
    "data['model'] = 'DNN (1 layer) - GloVe 200 dim'\n",
    "data['train_mse'] = round(train_mse, 3)\n",
    "data['train_time'] = train_time\n",
    "data['test_mse'] = round(test_mse, 3)\n",
    "\n",
    "regression_results.append(data)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                           model  train_mse  train_time  val_mse  test_mse\n0              RF TF-IDF 100 dim      0.225       7.449    1.402     1.610\n1              RF TF-IDF 200 dim      0.192       7.449    0.830     2.304\n2  DNN (1 layer) - GloVe 100 dim      0.097     134.798      NaN     1.926\n3  DNN (1 layer) - GloVe 200 dim      0.062     252.627      NaN     1.876",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>train_mse</th>\n      <th>train_time</th>\n      <th>val_mse</th>\n      <th>test_mse</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>RF TF-IDF 100 dim</td>\n      <td>0.225</td>\n      <td>7.449</td>\n      <td>1.402</td>\n      <td>1.610</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>RF TF-IDF 200 dim</td>\n      <td>0.192</td>\n      <td>7.449</td>\n      <td>0.830</td>\n      <td>2.304</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>DNN (1 layer) - GloVe 100 dim</td>\n      <td>0.097</td>\n      <td>134.798</td>\n      <td>NaN</td>\n      <td>1.926</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>DNN (1 layer) - GloVe 200 dim</td>\n      <td>0.062</td>\n      <td>252.627</td>\n      <td>NaN</td>\n      <td>1.876</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 93
    }
   ],
   "source": [
    "pd.DataFrame(regression_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF 100 dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"sequential_6\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_14 (Dense)             (None, 32)                3232      \n_________________________________________________________________\ndense_15 (Dense)             (None, 128)               4224      \n_________________________________________________________________\ndense_16 (Dense)             (None, 5)                 645       \n=================================================================\nTotal params: 8,101\nTrainable params: 8,101\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Dense(32, input_shape=(100,)),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(5, kernel_initializer='normal')\n",
    "])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "opt = 'rmsprop'\n",
    "\n",
    "model.compile(\n",
    "    optimizer=opt,\n",
    "    loss='mse',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/25\n94/94 [==============================] - 0s 1ms/step - loss: 0.1171\nEpoch 2/25\n94/94 [==============================] - 0s 898us/step - loss: 0.1009\nEpoch 3/25\n94/94 [==============================] - 0s 899us/step - loss: 0.0975\nEpoch 4/25\n94/94 [==============================] - 0s 969us/step - loss: 0.0958\nEpoch 5/25\n94/94 [==============================] - 0s 969us/step - loss: 0.0946\nEpoch 6/25\n94/94 [==============================] - 0s 948us/step - loss: 0.0935\nEpoch 7/25\n94/94 [==============================] - 0s 918us/step - loss: 0.0926\nEpoch 8/25\n94/94 [==============================] - 0s 992us/step - loss: 0.0919\nEpoch 9/25\n94/94 [==============================] - 0s 967us/step - loss: 0.0909\nEpoch 10/25\n94/94 [==============================] - 0s 978us/step - loss: 0.0899\nEpoch 11/25\n94/94 [==============================] - 0s 1ms/step - loss: 0.0891\nEpoch 12/25\n94/94 [==============================] - 0s 1ms/step - loss: 0.0883\nEpoch 13/25\n94/94 [==============================] - 0s 951us/step - loss: 0.0874\nEpoch 14/25\n94/94 [==============================] - 0s 978us/step - loss: 0.0865\nEpoch 15/25\n94/94 [==============================] - 0s 991us/step - loss: 0.0854\nEpoch 16/25\n94/94 [==============================] - 0s 863us/step - loss: 0.0845\nEpoch 17/25\n94/94 [==============================] - 0s 995us/step - loss: 0.0835\nEpoch 18/25\n94/94 [==============================] - 0s 948us/step - loss: 0.0828\nEpoch 19/25\n94/94 [==============================] - 0s 886us/step - loss: 0.0817\nEpoch 20/25\n94/94 [==============================] - 0s 981us/step - loss: 0.0809\nEpoch 21/25\n94/94 [==============================] - 0s 1ms/step - loss: 0.0798\nEpoch 22/25\n94/94 [==============================] - 0s 973us/step - loss: 0.0788\nEpoch 23/25\n94/94 [==============================] - 0s 1ms/step - loss: 0.0779\nEpoch 24/25\n94/94 [==============================] - 0s 981us/step - loss: 0.0771\nEpoch 25/25\n94/94 [==============================] - 0s 893us/step - loss: 0.0761\n"
    }
   ],
   "source": [
    "start = time.time()\n",
    "model.fit(tfidf100_train_matrix, train_labels,\n",
    "            epochs=25,\n",
    "            batch_size=32)\n",
    "\n",
    "end = time.time()\n",
    "train_time = parse_time(start, end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(1.352549150283239, 1.8496993987975952)"
     },
     "metadata": {},
     "execution_count": 96
    }
   ],
   "source": [
    "train_preds = model.predict(tfidf100_train_matrix)\n",
    "test_preds = model.predict(tfidf100_test_matrix)\n",
    "\n",
    "train_mse = mean_squared_error(np.argmax(train_preds, axis = 1), \n",
    "                                np.argmax(train_labels, axis=1))\n",
    "test_mse = mean_squared_error(np.argmax(test_preds, axis = 1), test_labels)\n",
    "\n",
    "train_mse, test_mse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'model': 'DNN (1 layer) - TF-IDF 100 terms',\n 'train_mse': 1.353,\n 'train_time': 2.818,\n 'test_mse': 1.85}"
     },
     "metadata": {},
     "execution_count": 97
    }
   ],
   "source": [
    "data = dict()\n",
    "data['model'] = 'DNN (1 layer) - TF-IDF 100 terms'\n",
    "data['train_mse'] = round(train_mse, 3)\n",
    "data['train_time'] = train_time\n",
    "data['test_mse'] = round(test_mse, 3)\n",
    "\n",
    "regression_results.append(data)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                              model  train_mse  train_time  val_mse  test_mse\n0                 RF TF-IDF 100 dim      0.225       7.449    1.402     1.610\n1                 RF TF-IDF 200 dim      0.192       7.449    0.830     2.304\n2     DNN (1 layer) - GloVe 100 dim      0.097     134.798      NaN     1.926\n3     DNN (1 layer) - GloVe 200 dim      0.062     252.627      NaN     1.876\n4  DNN (1 layer) - TF-IDF 100 terms      1.353       2.818      NaN     1.850",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>train_mse</th>\n      <th>train_time</th>\n      <th>val_mse</th>\n      <th>test_mse</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>RF TF-IDF 100 dim</td>\n      <td>0.225</td>\n      <td>7.449</td>\n      <td>1.402</td>\n      <td>1.610</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>RF TF-IDF 200 dim</td>\n      <td>0.192</td>\n      <td>7.449</td>\n      <td>0.830</td>\n      <td>2.304</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>DNN (1 layer) - GloVe 100 dim</td>\n      <td>0.097</td>\n      <td>134.798</td>\n      <td>NaN</td>\n      <td>1.926</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>DNN (1 layer) - GloVe 200 dim</td>\n      <td>0.062</td>\n      <td>252.627</td>\n      <td>NaN</td>\n      <td>1.876</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>DNN (1 layer) - TF-IDF 100 terms</td>\n      <td>1.353</td>\n      <td>2.818</td>\n      <td>NaN</td>\n      <td>1.850</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 98
    }
   ],
   "source": [
    "pd.DataFrame(regression_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GloVe 200 dim - regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"sequential_7\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding_1 (Embedding)      multiple                  2568600   \n_________________________________________________________________\nlstm (LSTM)                  (None, 128)               168448    \n_________________________________________________________________\ndense_17 (Dense)             (None, 5)                 645       \n=================================================================\nTotal params: 2,737,693\nTrainable params: 169,093\nNon-trainable params: 2,568,600\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "sequence200_input = Input(shape=(length_long_sentence,), dtype='int32')\n",
    "glove200_embedded_sequences = glove200_embedding_layer(sequence200_input)\n",
    "\n",
    "model = Sequential([\n",
    "    sequence200_input,\n",
    "    glove200_embedding_layer,\n",
    "    LSTM(units = 128),\n",
    "    Dense(5, kernel_initializer='normal')\n",
    "])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "opt = 'rmsprop'\n",
    "\n",
    "model.compile(\n",
    "    optimizer=opt,\n",
    "    loss='mse',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/10\n31/31 [==============================] - 62s 2s/step - loss: 0.1134 - val_loss: 0.1304\nEpoch 2/10\n31/31 [==============================] - 65s 2s/step - loss: 0.1029 - val_loss: 0.1392\nEpoch 3/10\n31/31 [==============================] - 65s 2s/step - loss: 0.0986 - val_loss: 0.1272\nEpoch 4/10\n31/31 [==============================] - 65s 2s/step - loss: 0.0952 - val_loss: 0.1244\nEpoch 5/10\n31/31 [==============================] - 64s 2s/step - loss: 0.0919 - val_loss: 0.1147\nEpoch 6/10\n31/31 [==============================] - 64s 2s/step - loss: 0.0900 - val_loss: 0.1204\nEpoch 7/10\n31/31 [==============================] - 65s 2s/step - loss: 0.0860 - val_loss: 0.1166\nEpoch 8/10\n31/31 [==============================] - 65s 2s/step - loss: 0.0828 - val_loss: 0.1115\nEpoch 9/10\n31/31 [==============================] - 65s 2s/step - loss: 0.0805 - val_loss: 0.1089\nEpoch 10/10\n31/31 [==============================] - 64s 2s/step - loss: 0.0779 - val_loss: 0.1675\n"
    }
   ],
   "source": [
    "start = time.time()\n",
    "model.fit(glove200_train, train_labels,\n",
    "            validation_data=(glove200_val, glove_val_labels),\n",
    "            epochs = 10,\n",
    "            batch_size=100)\n",
    "\n",
    "end = time.time()\n",
    "train_time = parse_time(start, end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(1.3058980339886705, 1.5791583166332666)"
     },
     "metadata": {},
     "execution_count": 101
    }
   ],
   "source": [
    "train_preds = model.predict(glove200_train)\n",
    "test_preds = model.predict(glove200_test)\n",
    "\n",
    "train_mse = mean_squared_error(np.argmax(train_preds, axis = 1), \n",
    "                                np.argmax(train_labels, axis=1))\n",
    "test_mse = mean_squared_error(np.argmax(test_preds, axis = 1), test_labels)\n",
    "\n",
    "train_mse, test_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'model': 'LSTM (1 layer) - GloVe 200 dim',\n 'train_mse': 1.306,\n 'train_time': 664.027,\n 'test_mse': 1.579}"
     },
     "metadata": {},
     "execution_count": 102
    }
   ],
   "source": [
    "data = dict()\n",
    "data['model'] = 'LSTM (1 layer) - GloVe 200 dim'\n",
    "data['train_mse'] = round(train_mse, 3)\n",
    "data['train_time'] = train_time\n",
    "data['test_mse'] = round(test_mse, 3)\n",
    "\n",
    "regression_results.append(data)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Glove 200 dim - classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"sequential_8\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding_1 (Embedding)      multiple                  2568600   \n_________________________________________________________________\nlstm_1 (LSTM)                (None, 128)               168448    \n_________________________________________________________________\ndense_18 (Dense)             (None, 5)                 645       \n=================================================================\nTotal params: 2,737,693\nTrainable params: 169,093\nNon-trainable params: 2,568,600\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "sequence200_input = Input(shape=(length_long_sentence,), dtype='int32')\n",
    "glove200_embedded_sequences = glove200_embedding_layer(sequence200_input)\n",
    "\n",
    "model = Sequential([\n",
    "    sequence200_input,\n",
    "    glove200_embedding_layer,\n",
    "    LSTM(units = 128),\n",
    "    Dense(5, activation='softmax')\n",
    "])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "opt = 'rmsprop'\n",
    "\n",
    "model.compile(\n",
    "    optimizer=opt,\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics = ['acc']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/10\n31/31 [==============================] - 62s 2s/step - loss: 1.1021 - acc: 0.6248 - val_loss: 1.1903 - val_acc: 0.6054\nEpoch 2/10\n31/31 [==============================] - 65s 2s/step - loss: 0.9958 - acc: 0.6435 - val_loss: 1.1764 - val_acc: 0.6354\nEpoch 3/10\n31/31 [==============================] - 64s 2s/step - loss: 0.9429 - acc: 0.6601 - val_loss: 1.0848 - val_acc: 0.6543\nEpoch 4/10\n31/31 [==============================] - 66s 2s/step - loss: 0.9145 - acc: 0.6638 - val_loss: 1.4295 - val_acc: 0.3906\nEpoch 5/10\n31/31 [==============================] - 66s 2s/step - loss: 0.8831 - acc: 0.6741 - val_loss: 1.5632 - val_acc: 0.4036\nEpoch 6/10\n31/31 [==============================] - 66s 2s/step - loss: 0.8733 - acc: 0.6814 - val_loss: 1.0340 - val_acc: 0.6683\nEpoch 7/10\n31/31 [==============================] - 65s 2s/step - loss: 0.8203 - acc: 0.6944 - val_loss: 1.5539 - val_acc: 0.2977\nEpoch 8/10\n31/31 [==============================] - 66s 2s/step - loss: 0.8143 - acc: 0.6898 - val_loss: 0.9943 - val_acc: 0.6583\nEpoch 9/10\n31/31 [==============================] - 66s 2s/step - loss: 0.7637 - acc: 0.7148 - val_loss: 1.4267 - val_acc: 0.3417\nEpoch 10/10\n31/31 [==============================] - 66s 2s/step - loss: 0.7297 - acc: 0.7244 - val_loss: 1.8565 - val_acc: 0.3017\n"
    }
   ],
   "source": [
    "start = time.time()\n",
    "model.fit(glove200_train, train_labels,\n",
    "            validation_data=(glove200_val, glove_val_labels),\n",
    "            epochs = 10,\n",
    "            batch_size=100)\n",
    "\n",
    "end = time.time()\n",
    "train_time = parse_time(start, end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate train F1 score\n",
    "train_preds = model.predict(glove200_train)\n",
    "train_f1 = f1_score(np.argmax(train_preds, axis=1), \n",
    "                    np.argmax(train_labels, axis=1), \n",
    "                    average='macro')\n",
    "# Generate test F1 score                    \n",
    "preds = model.predict(glove200_test)\n",
    "test_f1 = f1_score(np.argmax(preds, axis=1), test_labels, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'model': 'LSTM (1 layer) - GloVe 200 dim',\n 'train_f1': 0.24,\n 'train_time': 674.203,\n 'test_f1': 0.16}"
     },
     "metadata": {},
     "execution_count": 106
    }
   ],
   "source": [
    "data=dict()\n",
    "data['model'] = 'LSTM (1 layer) - GloVe 200 dim'\n",
    "data['train_f1'] = round(train_f1, 3)\n",
    "data['train_time'] = train_time\n",
    "data['test_f1'] = round(test_f1, 3)\n",
    "classifier_results.append(data)\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                            model  train_f1  train_time  val_f1  test_f1\n0             RF TF-IDF 100 terms     0.985       1.024   0.244    0.019\n1             RF TF-IDF 200 terms     0.998       1.240   0.249    0.020\n2   DNN (1 layer) - GloVe 100 dim     1.000     129.973     NaN    0.307\n3   DNN (1 layer) - GloVe 200 dim     1.000     259.123     NaN    0.280\n4  LSTM (1 layer) - GloVe 200 dim     0.240     674.203     NaN    0.160",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>train_f1</th>\n      <th>train_time</th>\n      <th>val_f1</th>\n      <th>test_f1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>RF TF-IDF 100 terms</td>\n      <td>0.985</td>\n      <td>1.024</td>\n      <td>0.244</td>\n      <td>0.019</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>RF TF-IDF 200 terms</td>\n      <td>0.998</td>\n      <td>1.240</td>\n      <td>0.249</td>\n      <td>0.020</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>DNN (1 layer) - GloVe 100 dim</td>\n      <td>1.000</td>\n      <td>129.973</td>\n      <td>NaN</td>\n      <td>0.307</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>DNN (1 layer) - GloVe 200 dim</td>\n      <td>1.000</td>\n      <td>259.123</td>\n      <td>NaN</td>\n      <td>0.280</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>LSTM (1 layer) - GloVe 200 dim</td>\n      <td>0.240</td>\n      <td>674.203</td>\n      <td>NaN</td>\n      <td>0.160</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 107
    }
   ],
   "source": [
    "pd.DataFrame(classifier_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GloVe 100 dim - classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"sequential_9\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding (Embedding)        multiple                  1284300   \n_________________________________________________________________\nlstm_2 (LSTM)                (None, 128)               117248    \n_________________________________________________________________\ndense_19 (Dense)             (None, 5)                 645       \n=================================================================\nTotal params: 1,402,193\nTrainable params: 117,893\nNon-trainable params: 1,284,300\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "sequence100_input = Input(shape=(length_long_sentence,), dtype='int32')\n",
    "glove100_embedded_sequences = glove100_embedding_layer(sequence100_input)\n",
    "\n",
    "model = Sequential([\n",
    "    #sequence100_input,\n",
    "    glove100_embedding_layer,\n",
    "    LSTM(units = 128),\n",
    "    Dense(5, activation='softmax')\n",
    "])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "opt = 'rmsprop'\n",
    "\n",
    "model.compile(\n",
    "    optimizer=opt,\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics = ['acc']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/20\n31/31 [==============================] - 57s 2s/step - loss: 1.1225 - acc: 0.6135 - val_loss: 1.2448 - val_acc: 0.5784\nEpoch 2/20\n31/31 [==============================] - 61s 2s/step - loss: 1.0376 - acc: 0.6408 - val_loss: 1.0086 - val_acc: 0.6464\nEpoch 3/20\n31/31 [==============================] - 61s 2s/step - loss: 0.9908 - acc: 0.6488 - val_loss: 1.2134 - val_acc: 0.6414\nEpoch 4/20\n31/31 [==============================] - 62s 2s/step - loss: 0.9890 - acc: 0.6475 - val_loss: 1.0891 - val_acc: 0.6014\nEpoch 5/20\n31/31 [==============================] - 61s 2s/step - loss: 0.9417 - acc: 0.6614 - val_loss: 1.4808 - val_acc: 0.6304\nEpoch 6/20\n31/31 [==============================] - 61s 2s/step - loss: 0.9599 - acc: 0.6574 - val_loss: 1.0478 - val_acc: 0.5644\nEpoch 7/20\n31/31 [==============================] - 61s 2s/step - loss: 0.9134 - acc: 0.6608 - val_loss: 1.2953 - val_acc: 0.6334\nEpoch 8/20\n31/31 [==============================] - 62s 2s/step - loss: 0.8973 - acc: 0.6714 - val_loss: 1.1434 - val_acc: 0.4336\nEpoch 9/20\n31/31 [==============================] - 62s 2s/step - loss: 0.8775 - acc: 0.6758 - val_loss: 1.4056 - val_acc: 0.3756\nEpoch 10/20\n31/31 [==============================] - 61s 2s/step - loss: 0.8550 - acc: 0.6794 - val_loss: 1.2115 - val_acc: 0.5175\nEpoch 11/20\n31/31 [==============================] - 61s 2s/step - loss: 0.8234 - acc: 0.6868 - val_loss: 1.1178 - val_acc: 0.6653\nEpoch 12/20\n31/31 [==============================] - 61s 2s/step - loss: 0.8039 - acc: 0.6991 - val_loss: 1.1384 - val_acc: 0.6593\nEpoch 13/20\n31/31 [==============================] - 61s 2s/step - loss: 0.7911 - acc: 0.7068 - val_loss: 1.0092 - val_acc: 0.6104\nEpoch 14/20\n31/31 [==============================] - 61s 2s/step - loss: 0.7599 - acc: 0.7088 - val_loss: 1.0194 - val_acc: 0.6014\nEpoch 15/20\n31/31 [==============================] - 61s 2s/step - loss: 0.7250 - acc: 0.7278 - val_loss: 1.2390 - val_acc: 0.6623\nEpoch 16/20\n31/31 [==============================] - 61s 2s/step - loss: 0.7253 - acc: 0.7218 - val_loss: 1.0011 - val_acc: 0.6474\nEpoch 17/20\n31/31 [==============================] - 61s 2s/step - loss: 0.6751 - acc: 0.7478 - val_loss: 1.0090 - val_acc: 0.6264\nEpoch 18/20\n31/31 [==============================] - 61s 2s/step - loss: 0.6247 - acc: 0.7621 - val_loss: 1.1440 - val_acc: 0.6533\nEpoch 19/20\n31/31 [==============================] - 62s 2s/step - loss: 0.6052 - acc: 0.7667 - val_loss: 1.2571 - val_acc: 0.5774\nEpoch 20/20\n31/31 [==============================] - 61s 2s/step - loss: 0.5675 - acc: 0.7837 - val_loss: 1.1504 - val_acc: 0.6464\n"
    }
   ],
   "source": [
    "start = time.time()\n",
    "model.fit(glove200_train, train_labels,\n",
    "            validation_data=(glove100_val, glove_val_labels),\n",
    "            epochs = 20,\n",
    "            batch_size=100)\n",
    "\n",
    "end = time.time()\n",
    "train_time = parse_time(start, end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate train F1 score\n",
    "train_preds = model.predict(glove100_train)\n",
    "train_f1 = f1_score(np.argmax(train_preds, axis=1), \n",
    "                    np.argmax(train_labels, axis=1), \n",
    "                    average='macro')\n",
    "# Generate test F1 score                    \n",
    "preds = model.predict(glove100_test)\n",
    "test_f1 = f1_score(np.argmax(preds, axis=1), test_labels, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'model': 'LSTM (1 layer) - GloVe 100 dim',\n 'train_f1': 0.485,\n 'train_time': 1258.86,\n 'test_f1': 0.277}"
     },
     "metadata": {},
     "execution_count": 111
    }
   ],
   "source": [
    "data=dict()\n",
    "data['model'] = 'LSTM (1 layer) - GloVe 100 dim'\n",
    "data['train_f1'] = round(train_f1, 3)\n",
    "data['train_time'] = train_time\n",
    "data['test_f1'] = round(test_f1, 3)\n",
    "classifier_results.append(data)\n",
    "data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-layer LSTM - GloVe 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"sequential_10\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding (Embedding)        multiple                  1284300   \n_________________________________________________________________\nlstm_3 (LSTM)                (None, 1707, 128)         117248    \n_________________________________________________________________\nlstm_4 (LSTM)                (None, 1707, 128)         131584    \n_________________________________________________________________\nlstm_5 (LSTM)                (None, 256)               394240    \n_________________________________________________________________\ndense_20 (Dense)             (None, 5)                 1285      \n=================================================================\nTotal params: 1,928,657\nTrainable params: 644,357\nNon-trainable params: 1,284,300\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "sequence100_input = Input(shape=(length_long_sentence,), dtype='int32')\n",
    "glove100_embedded_sequences = glove100_embedding_layer(sequence100_input)\n",
    "\n",
    "model = Sequential([\n",
    "    #sequence100_input,\n",
    "    glove100_embedding_layer,\n",
    "    LSTM(units = 128, return_sequences=True),\n",
    "    LSTM(units=256),\n",
    "    Dense(5, activation='softmax')\n",
    "])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "opt = 'rmsprop'\n",
    "\n",
    "model.compile(\n",
    "    optimizer=opt,\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics = ['acc']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/15\n94/94 [==============================] - 458s 5s/step - loss: 1.1209 - acc: 0.6231 - val_loss: 1.0305 - val_acc: 0.6563\nEpoch 2/15\n94/94 [==============================] - 456s 5s/step - loss: 1.0189 - acc: 0.6378 - val_loss: 0.9940 - val_acc: 0.6424\nEpoch 3/15\n94/94 [==============================] - 457s 5s/step - loss: 0.9608 - acc: 0.6521 - val_loss: 0.9881 - val_acc: 0.6344\nEpoch 4/15\n94/94 [==============================] - 455s 5s/step - loss: 0.9307 - acc: 0.6644 - val_loss: 1.0068 - val_acc: 0.6583\nEpoch 5/15\n94/94 [==============================] - 461s 5s/step - loss: 0.9023 - acc: 0.6634 - val_loss: 0.9587 - val_acc: 0.6573\nEpoch 6/15\n40/94 [===========>..................] - ETA: 3:54 - loss: 0.8367 - acc: 0.6953"
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-113-fb896ba47040>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m model.fit(glove100_train, train_labels,\n\u001b[0m\u001b[1;32m      3\u001b[0m             \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglove100_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglove_val_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m             \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             batch_size=32)\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1659\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m     \"\"\"\n\u001b[0;32m-> 1661\u001b[0;31m     return self._call_flat(\n\u001b[0m\u001b[1;32m   1662\u001b[0m         (t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1743\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1745\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1746\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    591\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    594\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "model.fit(glove100_train, train_labels,\n",
    "            validation_data=(glove100_val, glove_val_labels),\n",
    "            epochs = 15,\n",
    "            batch_size=32)\n",
    "\n",
    "end = time.time()\n",
    "train_time = parse_time(start, end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate train F1 score\n",
    "train_preds = model.predict(glove100_train)\n",
    "train_f1 = f1_score(np.argmax(train_preds, axis=1), \n",
    "                    np.argmax(train_labels, axis=1), \n",
    "                    average='macro')\n",
    "# Generate test F1 score                    \n",
    "preds = model.predict(glove100_test)\n",
    "lstm_preds = model.predict(glove100_test)\n",
    "test_f1 = f1_score(np.argmax(preds, axis=1), test_labels, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'model': 'LSTM (3 layers) - GloVe 100 dim',\n 'train_f1': 0.851,\n 'train_time': 1701.62,\n 'test_f1': 0.283}"
     },
     "metadata": {},
     "execution_count": 115
    }
   ],
   "source": [
    "data=dict()\n",
    "data['model'] = 'LSTM (2 layers) - GloVe 100 dim'\n",
    "data['train_f1'] = round(train_f1, 3)\n",
    "data['train_time'] = train_time\n",
    "data['test_f1'] = round(test_f1, 3)\n",
    "classifier_results.append(data)\n",
    "data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bidirection LSTM - GloVe 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"sequential_11\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding (Embedding)        multiple                  431500    \n_________________________________________________________________\nbidirectional (Bidirectional (None, 256)               234496    \n_________________________________________________________________\ndense_21 (Dense)             (None, 5)                 1285      \n=================================================================\nTotal params: 667,281\nTrainable params: 235,781\nNon-trainable params: 431,500\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "sequence100_input = Input(shape=(length_long_sentence,), dtype='int32')\n",
    "glove100_embedded_sequences = glove100_embedding_layer(sequence100_input)\n",
    "\n",
    "model = Sequential([\n",
    "    #sequence100_input,\n",
    "    glove100_embedding_layer,\n",
    "    Bidirectional(LSTM(units = 128)),\n",
    "    Dense(5, activation='softmax')\n",
    "])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "opt = RMSprop()\n",
    "\n",
    "model.compile(\n",
    "    optimizer=opt,\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics = ['acc']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/15\n23/23 [==============================] - 33s 1s/step - loss: 1.3786 - acc: 0.4771 - val_loss: 1.2479 - val_acc: 0.5104\nEpoch 2/15\n23/23 [==============================] - 32s 1s/step - loss: 1.2309 - acc: 0.5423 - val_loss: 1.2514 - val_acc: 0.5311\nEpoch 3/15\n23/23 [==============================] - 33s 1s/step - loss: 1.1518 - acc: 0.5589 - val_loss: 1.1555 - val_acc: 0.5602\nEpoch 4/15\n23/23 [==============================] - 33s 1s/step - loss: 1.0780 - acc: 0.5770 - val_loss: 1.1921 - val_acc: 0.5519\nEpoch 5/15\n23/23 [==============================] - 33s 1s/step - loss: 1.0621 - acc: 0.5908 - val_loss: 1.2770 - val_acc: 0.5560\nEpoch 6/15\n23/23 [==============================] - 33s 1s/step - loss: 0.9829 - acc: 0.6366 - val_loss: 1.2435 - val_acc: 0.4855\nEpoch 7/15\n23/23 [==============================] - 32s 1s/step - loss: 0.9193 - acc: 0.6505 - val_loss: 1.2692 - val_acc: 0.4896\nEpoch 8/15\n23/23 [==============================] - 34s 1s/step - loss: 0.9042 - acc: 0.6546 - val_loss: 1.2166 - val_acc: 0.5104\nEpoch 9/15\n23/23 [==============================] - 33s 1s/step - loss: 0.7867 - acc: 0.7101 - val_loss: 1.3910 - val_acc: 0.5353\nEpoch 10/15\n23/23 [==============================] - 33s 1s/step - loss: 0.7358 - acc: 0.7323 - val_loss: 1.7673 - val_acc: 0.5477\nEpoch 11/15\n23/23 [==============================] - 33s 1s/step - loss: 0.7153 - acc: 0.7573 - val_loss: 1.4173 - val_acc: 0.5228\nEpoch 12/15\n23/23 [==============================] - 32s 1s/step - loss: 0.5962 - acc: 0.8044 - val_loss: 1.4399 - val_acc: 0.4647\nEpoch 13/15\n23/23 [==============================] - 31s 1s/step - loss: 0.5735 - acc: 0.7947 - val_loss: 1.6478 - val_acc: 0.5145\nEpoch 14/15\n23/23 [==============================] - 31s 1s/step - loss: 0.5544 - acc: 0.8280 - val_loss: 1.5957 - val_acc: 0.4025\nEpoch 15/15\n23/23 [==============================] - 32s 1s/step - loss: 0.4415 - acc: 0.8488 - val_loss: 1.7234 - val_acc: 0.5187\n"
    }
   ],
   "source": [
    "start = time.time()\n",
    "model.fit(glove100_train, train_labels,\n",
    "            validation_data=(glove100_val, glove_val_labels),\n",
    "            epochs = 15,\n",
    "            batch_size=32)\n",
    "\n",
    "end = time.time()\n",
    "train_time = parse_time(start, end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate train F1 score\n",
    "train_preds = model.predict(glove100_train)\n",
    "train_f1 = f1_score(np.argmax(train_preds, axis=1), \n",
    "                    np.argmax(train_labels, axis=1), \n",
    "                    average='macro')\n",
    "# Generate test F1 score                    \n",
    "preds = model.predict(glove100_test)\n",
    "bidirectional_preds = model.predict(glove100_test)\n",
    "test_f1 = f1_score(np.argmax(preds, axis=1), test_labels, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'model': 'Bidirectional (1 layer) - GloVe 100 dim',\n 'train_f1': 0.762,\n 'train_time': 511.209,\n 'test_f1': 0.263}"
     },
     "metadata": {},
     "execution_count": 119
    }
   ],
   "source": [
    "data=dict()\n",
    "data['model'] = 'Bidirectional (1 layer) - GloVe 100 dim'\n",
    "data['train_f1'] = round(train_f1, 3)\n",
    "data['train_time'] = train_time\n",
    "data['test_f1'] = round(test_f1, 3)\n",
    "classifier_results.append(data)\n",
    "data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conv1D classification experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GloVe 100 dim - classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"sequential_13\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding (Embedding)        multiple                  431500    \n_________________________________________________________________\nconv1d_2 (Conv1D)            (None, 1705, 128)         38528     \n_________________________________________________________________\nleaky_re_lu_2 (LeakyReLU)    (None, 1705, 128)         0         \n_________________________________________________________________\nmax_pooling1d_2 (MaxPooling1 (None, 568, 128)          0         \n_________________________________________________________________\nbatch_normalization_2 (Batch (None, 568, 128)          512       \n_________________________________________________________________\nconv1d_3 (Conv1D)            (None, 566, 128)          49280     \n_________________________________________________________________\nleaky_re_lu_3 (LeakyReLU)    (None, 566, 128)          0         \n_________________________________________________________________\nmax_pooling1d_3 (MaxPooling1 (None, 188, 128)          0         \n_________________________________________________________________\nbatch_normalization_3 (Batch (None, 188, 128)          512       \n_________________________________________________________________\nflatten_5 (Flatten)          (None, 24064)             0         \n_________________________________________________________________\ndense_24 (Dense)             (None, 128)               3080320   \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 128)               0         \n_________________________________________________________________\ndense_25 (Dense)             (None, 5)                 645       \n=================================================================\nTotal params: 3,601,297\nTrainable params: 3,169,285\nNon-trainable params: 432,012\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "sequence100_input = Input(shape=(length_long_sentence,), dtype='int32')\n",
    "glove100_embedded_sequences = glove100_embedding_layer(sequence100_input)\n",
    "\n",
    "model = Sequential([\n",
    "    #sequence100_input,\n",
    "    glove100_embedding_layer,\n",
    "    Conv1D(128, 3),\n",
    "    LeakyReLU(),\n",
    "    MaxPooling1D(3),\n",
    "    BatchNormalization(),\n",
    "    Conv1D(128, 3),\n",
    "    LeakyReLU(),\n",
    "    MaxPooling1D(3),\n",
    "    BatchNormalization(),\n",
    "    #GlobalMaxPooling1D(),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(5, activation='softmax')\n",
    "])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "opt = SGD(lr=0.001)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=opt,\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics = ['acc']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/15\n8/8 [==============================] - 3s 380ms/step - loss: 1.8325 - acc: 0.3842 - val_loss: 1.5558 - val_acc: 0.4772\nEpoch 2/15\n8/8 [==============================] - 3s 402ms/step - loss: 1.5436 - acc: 0.4688 - val_loss: 1.5669 - val_acc: 0.4855\nEpoch 3/15\n8/8 [==============================] - 3s 376ms/step - loss: 1.4186 - acc: 0.5007 - val_loss: 1.5670 - val_acc: 0.4647\nEpoch 4/15\n8/8 [==============================] - 3s 386ms/step - loss: 1.3592 - acc: 0.5021 - val_loss: 1.5665 - val_acc: 0.4564\nEpoch 5/15\n8/8 [==============================] - 3s 372ms/step - loss: 1.2653 - acc: 0.5215 - val_loss: 1.5690 - val_acc: 0.4232\nEpoch 6/15\n8/8 [==============================] - 3s 391ms/step - loss: 1.2081 - acc: 0.5381 - val_loss: 1.5600 - val_acc: 0.4896\nEpoch 7/15\n8/8 [==============================] - 3s 367ms/step - loss: 1.1433 - acc: 0.5645 - val_loss: 1.5622 - val_acc: 0.4813\nEpoch 8/15\n8/8 [==============================] - 3s 367ms/step - loss: 1.1120 - acc: 0.6033 - val_loss: 1.5664 - val_acc: 0.4855\nEpoch 9/15\n8/8 [==============================] - 3s 390ms/step - loss: 1.0790 - acc: 0.6130 - val_loss: 1.5513 - val_acc: 0.4979\nEpoch 10/15\n8/8 [==============================] - 3s 384ms/step - loss: 1.0636 - acc: 0.6227 - val_loss: 1.5622 - val_acc: 0.4896\nEpoch 11/15\n8/8 [==============================] - 3s 391ms/step - loss: 1.0252 - acc: 0.6269 - val_loss: 1.5476 - val_acc: 0.4938\nEpoch 12/15\n8/8 [==============================] - 3s 384ms/step - loss: 0.9968 - acc: 0.6297 - val_loss: 1.5420 - val_acc: 0.4938\nEpoch 13/15\n8/8 [==============================] - 3s 385ms/step - loss: 0.9489 - acc: 0.6560 - val_loss: 1.5331 - val_acc: 0.4979\nEpoch 14/15\n8/8 [==============================] - 3s 387ms/step - loss: 0.9617 - acc: 0.6644 - val_loss: 1.5252 - val_acc: 0.5104\nEpoch 15/15\n8/8 [==============================] - 3s 380ms/step - loss: 0.9237 - acc: 0.6560 - val_loss: 1.5364 - val_acc: 0.4938\n"
    }
   ],
   "source": [
    "start = time.time()\n",
    "model.fit(glove100_train, train_labels,\n",
    "            validation_data=(glove100_val, glove_val_labels),\n",
    "            epochs = 15,\n",
    "            batch_size=100)\n",
    "\n",
    "end = time.time()\n",
    "train_time = parse_time(start, end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate train F1 score\n",
    "train_preds = model.predict(glove100_train)\n",
    "train_f1 = f1_score(np.argmax(train_preds, axis=1), \n",
    "                    np.argmax(train_labels, axis=1), \n",
    "                    average='macro')\n",
    "# Generate test F1 score                    \n",
    "preds = model.predict(glove100_test)\n",
    "cnn_preds = model.predict(glove100_test)\n",
    "test_f1 = f1_score(np.argmax(preds, axis=1), test_labels, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(0.3349662143641968, 0.21757989193158442)"
     },
     "metadata": {},
     "execution_count": 129
    }
   ],
   "source": [
    "train_f1, test_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'model': 'CNN (2 layers) - GloVe 100 dim',\n 'train_f1': 0.335,\n 'train_time': 53.287,\n 'test_f1': 0.218}"
     },
     "metadata": {},
     "execution_count": 130
    }
   ],
   "source": [
    "data=dict()\n",
    "data['model'] = 'CNN (2 layers) - GloVe 100 dim'\n",
    "data['train_f1'] = round(train_f1, 3)\n",
    "data['train_time'] = train_time\n",
    "data['test_f1'] = round(test_f1, 3)\n",
    "classifier_results.append(data)\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                                     model  train_f1  train_time  val_f1  \\\n0                      RF TF-IDF 100 terms     0.993       0.292   0.272   \n1                      RF TF-IDF 200 terms     0.999       0.325   0.274   \n2            DNN (1 layer) - GloVe 100 dim     1.000      34.214     NaN   \n3            DNN (1 layer) - GloVe 200 dim     1.000      62.484     NaN   \n4           LSTM (1 layer) - GloVe 200 dim     0.545     165.011     NaN   \n5           LSTM (1 layer) - GloVe 100 dim     0.600     308.011     NaN   \n6          LSTM (3 layers) - GloVe 100 dim     0.851    1701.620     NaN   \n7  Bidirectional (1 layer) - GloVe 100 dim     0.762     511.209     NaN   \n8           CNN (2 layers) - GloVe 100 dim     0.239      52.466     NaN   \n9           CNN (2 layers) - GloVe 100 dim     0.335      53.287     NaN   \n\n   test_f1  \n0    0.040  \n1    0.016  \n2    0.269  \n3    0.263  \n4    0.252  \n5    0.281  \n6    0.283  \n7    0.263  \n8    0.127  \n9    0.218  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>train_f1</th>\n      <th>train_time</th>\n      <th>val_f1</th>\n      <th>test_f1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>RF TF-IDF 100 terms</td>\n      <td>0.993</td>\n      <td>0.292</td>\n      <td>0.272</td>\n      <td>0.040</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>RF TF-IDF 200 terms</td>\n      <td>0.999</td>\n      <td>0.325</td>\n      <td>0.274</td>\n      <td>0.016</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>DNN (1 layer) - GloVe 100 dim</td>\n      <td>1.000</td>\n      <td>34.214</td>\n      <td>NaN</td>\n      <td>0.269</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>DNN (1 layer) - GloVe 200 dim</td>\n      <td>1.000</td>\n      <td>62.484</td>\n      <td>NaN</td>\n      <td>0.263</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>LSTM (1 layer) - GloVe 200 dim</td>\n      <td>0.545</td>\n      <td>165.011</td>\n      <td>NaN</td>\n      <td>0.252</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>LSTM (1 layer) - GloVe 100 dim</td>\n      <td>0.600</td>\n      <td>308.011</td>\n      <td>NaN</td>\n      <td>0.281</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>LSTM (3 layers) - GloVe 100 dim</td>\n      <td>0.851</td>\n      <td>1701.620</td>\n      <td>NaN</td>\n      <td>0.283</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Bidirectional (1 layer) - GloVe 100 dim</td>\n      <td>0.762</td>\n      <td>511.209</td>\n      <td>NaN</td>\n      <td>0.263</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>CNN (2 layers) - GloVe 100 dim</td>\n      <td>0.239</td>\n      <td>52.466</td>\n      <td>NaN</td>\n      <td>0.127</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>CNN (2 layers) - GloVe 100 dim</td>\n      <td>0.335</td>\n      <td>53.287</td>\n      <td>NaN</td>\n      <td>0.218</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 131
    }
   ],
   "source": [
    "pd.DataFrame(classifier_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble model scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM\n",
    "\n",
    "# Dense\n",
    "\n",
    "# CNN\n",
    "\n",
    "# Bidrection LSTM"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38264bit0c31753cb4904f759510df829f98c315",
   "display_name": "Python 3.8.2 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}